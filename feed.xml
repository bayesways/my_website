<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://bayesways.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://bayesways.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-05-28T23:11:37+00:00</updated><id>https://bayesways.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Would you hire GPT as an equity analyst?</title><link href="https://bayesways.github.io/blog/2024/Would-you-hire-GPT-as-an-equity-analyst/" rel="alternate" type="text/html" title="Would you hire GPT as an equity analyst?"/><published>2024-05-26T00:00:00+00:00</published><updated>2024-05-26T00:00:00+00:00</updated><id>https://bayesways.github.io/blog/2024/Would%20you%20hire%20GPT%20as%20an%20equity%20analyst</id><content type="html" xml:base="https://bayesways.github.io/blog/2024/Would-you-hire-GPT-as-an-equity-analyst/"><![CDATA[<p>This week I am looking at a new paper “<a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4835311">Financial Statement Analysis with LLMs</a>” from a Chicago Booth team. The paper tries to rigorously test whether LLMs can do fundamental analysis. Before we get into the meat of the paper, we note that the context matters here. The human analysts historically have a 53% accuracy of predicting correctly. In other words, a machine needs to do be 3% better than random to beat the human specialists. Naturally one wonders how come the specialists only have 53% accuracy. So we note that 53% is the accuracy of the median of the analysts. I don’t have the raw data but I imagine the best analysts score meaningfully above 53%. In any case this means that in any given moment about half of the analysts are right and the other half are wrong, which reminds me of the old advertisement saying “only half of my advertisement budget works, problem is I don’t know which half” (attributed to <a href="https://en.wikipedia.org/wiki/John_Wanamaker">J. Wanamaker</a>). Anyway, let’s leave aside the absolute accuracy for the remaining of this post, and let’s focus on the relative accuracy of machine versus human. Let’s dive into the specifics of the paper.</p> <p>First the results, the paper finds that the LLMs are worse than humans out of the box, but better than humans if tweaked on a specific task. To be specific, LLMs, in this paper, mean GPT-4-Turbo. To prove this, the authors set up an experiment. Used historical data of financial statements, without any additional context, and removing names and years from the dataset. This was done to minimize <a href="https://en.wikipedia.org/wiki/Leakage_(machine_learning)">ML leakage</a>, i.e. a form of model cheating where contextual information from the future leaks into the training set that allows the model to cheat when making a prediction. The authors wanted to test the LLMs ability to analyze the pure numbers from a financial statement. <em>The target variable is annual directional change of earnings</em>, i.e. predicting whether the next year’s earnings will go up or down relative to the current year. The dataset comes from <a href="https://www.marketplace.spglobal.com/en/datasets/compustat-financials-(8)">Compustat</a> which “provides standardized North American and global financial statements and market data for over 80,000 active and inactive publicly traded companies that financial professionals have relied on for over 50 years.” The paper filtered the data to the years 1983-2021 with about 40,000 observations for about 3,000 distinct companies.</p> <p>They compared 2 LLM methods against the human’s 53% accuracy. The first was a simple prompt method which performed at 49%. The second was a chain-of-thought setup (CoT) which performed at 60%. <strong>So we can conclude that as far as financial statement analysis goes, LLMs + CoT prompting outperforms human consensus.</strong> We note again the inclusion of the word “consensus”, which means that the LLMs are not better than the best humans necessarily, but are better than the average. This begs the question “is the consensus representative of the humans’ ability in this space”. I am not sure about this, since there is no discussion in the paper about the criteria used to pick the sample for this paper. But one can imagine that the 53% figure is sensitive to the choice of the analysts that were used in the data pool. It would be interesting to see more specifics around this in order to understand not only what is the accuracy of the average analyst but also how do the machines fare against the best humans, not just the average.</p> <p>There are some additional interesting results in the paper that put the human consensus accuracy in the context of bias variance tradeoff. The authors created 3 more forecasting methods with the corresponding accuracy scores (in parenthesis):</p> <ul> <li>a logistic regression trained on an expanded set of features (<em>53%</em>)</li> <li>a NN trained on the smaller set of features extracted from the documents fed to the LLM (<em>59%</em>)</li> <li>an NN trained on the expanded set of features (<em>63%</em>)</li> </ul> <p>The conclusion of this is: 1) the average humans are comparable to a logistic regression which is consistent with prior <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1528987">literature</a> 2) more sophisticated algorithms outperform the average human by a considerable margin, but we don’t know if they beat the best humans 4) LLMs are general purpose learners that can be adapted to perform on par with specialized algorithms</p> <h2 id="references">References</h2> <ul> <li>Kim, Alex, Maximilian Muhn, and Valeri V. Nikolaev. “Financial Statement Analysis with Large Language Models.” <em>Chicago Booth Research Paper Forthcoming, Fama-Miller Working Paper</em> (2024). <a href="https://bfi.uchicago.edu/wp-content/uploads/2024/05/BFI_WP_2024-65.pdf">PDF</a></li> <li>Bradshaw, Mark T and Drake, Michael S. and Myers, James N. and Myers, Linda A., A Re-Examination of Analysts’ Superiority over Time-Series Forecasts of Annual Earnings (2012). Review of Accounting Studies, Vol. 17, No. 4, 2012, <a href="https://care-mendoza.nd.edu/assets/152185/bradshawpaper.pdf">PDF</a></li> </ul>]]></content><author><name></name></author><category term="llm"/><summary type="html"><![CDATA[This week I am looking at a new paper “Financial Statement Analysis with LLMs” from a Chicago Booth team. The paper tries to rigorously test whether LLMs can do fundamental analysis. Before we get into the meat of the paper, we note that the context matters here. The human analysts historically have a 53% accuracy of predicting correctly. In other words, a machine needs to do be 3% better than random to beat the human specialists. Naturally one wonders how come the specialists only have 53% accuracy. So we note that 53% is the accuracy of the median of the analysts. I don’t have the raw data but I imagine the best analysts score meaningfully above 53%. In any case this means that in any given moment about half of the analysts are right and the other half are wrong, which reminds me of the old advertisement saying “only half of my advertisement budget works, problem is I don’t know which half” (attributed to J. Wanamaker). Anyway, let’s leave aside the absolute accuracy for the remaining of this post, and let’s focus on the relative accuracy of machine versus human. Let’s dive into the specifics of the paper.]]></summary></entry><entry><title type="html">How I spend my weekend building a tool with ChatGPT</title><link href="https://bayesways.github.io/blog/2024/How-I-spend-my-weekend-building-a-tool-with-ChatGPT/" rel="alternate" type="text/html" title="How I spend my weekend building a tool with ChatGPT"/><published>2024-02-10T00:00:00+00:00</published><updated>2024-02-10T00:00:00+00:00</updated><id>https://bayesways.github.io/blog/2024/How%20I%20spend%20my%20weekend%20building%20a%20tool%20with%20ChatGPT</id><content type="html" xml:base="https://bayesways.github.io/blog/2024/How-I-spend-my-weekend-building-a-tool-with-ChatGPT/"><![CDATA[<h3 id="summary">Summary</h3> <p>I’ve been using ChatGPT for things I know the answer to and it’s working fairly well. I’ve been looking for ways to go further and start using it to explore things I do not know as well. This weekend I had a good excuse to do that.</p> <p>I wanted to transfer my saved places from a google account to another account. Surprisingly Google doesn’t give you that option. That was actually the perfect excuse to use ChatGPT to do so build a tool over the weekend for me.</p> <p>My goal here is not only to build a new tool, but to also test ChatGPT’s abilities. I am interested to understand how could ChatGPT function as a general purpose <em>learning copilot</em>. I am looking for things like its usefulness in breaking a problem down, implementing each step, explaining along the way its thinking, zooming in as needed to explain a new concept, zooming out to review the plan so far and so on. To this end I ask it a mix a questions of things I know about and things I know less about. I found that ChatGPT provides value in both cases.</p> <p><strong>Conclusions</strong> ChatGPT can break down and trouble shoot fairly simple problems and suggest reasonable solutions. It’s OK at zooming in to troubleshoot a specific issue, and zooming back out to continue the larger plan, but it helps to remind it. In that sense it’s certainly a useful learning copilot and I imagine it can be significantly more helpful as we finetune it to specific use cases.</p> <p>Another interesting insight for me was that by asking it questions for which I know the answer to, I usually ended up learning something new. By prompting the LLM to suggest more than one solutions to a problem, we can expand our creativity. I believe this use case can be a really helpful feature of LLMs. LLMs operate quite differently from humans. One of their unique strengths is the ability to bring immense volumes of data within the context of a conversation very quickly. Humans can use this ability to expand the set of approaches to a specific problem, hence allowing us to not just to arrive faster to the solution, but potentially arrive to a better solution or more than one solutions.</p> <h3 id="development-log">Development Log</h3> <p>In the following section I describe my experience “working with” ChatGPT to build a new tool. The purpose of the tool is to help transfer a list of saved places from one Google account to another.</p> <p>I am an OK programmer, but not a full stack developer. I figured I’ll need some help with this. I’ll make a point to ask questions at each step, including to things I know the answer to. I opened ChatGPT and explained the task. It said that the recommended way was to manually enter each item in. <em>But</em>, it also gave an alternative approach which would require “programming knowledge and familiarity with Google’s APIs.”. Let’s do that, I said.</p> <p>Great, it said here is an approach.</p> <p>Here is an example list of saved places</p> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">

</span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"FeatureCollection"</span><span class="p">,</span><span class="w">

</span><span class="nl">"features"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">

</span><span class="p">{</span><span class="w">

</span><span class="nl">"geometry"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">

</span><span class="nl">"coordinates"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">

</span><span class="mf">2.3567354</span><span class="p">,</span><span class="w">

</span><span class="mf">48.8517232</span><span class="w">

</span><span class="p">],</span><span class="w">

</span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Point"</span><span class="w">

</span><span class="p">},</span><span class="w">

</span><span class="nl">"properties"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">

</span><span class="nl">"date"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2022-07-09T17:15:34Z"</span><span class="p">,</span><span class="w">

</span><span class="nl">"google_maps_url"</span><span class="p">:</span><span class="w"> </span><span class="s2">"http://maps.google.com/?cid=3697878718076448074"</span><span class="p">,</span><span class="w">

</span><span class="nl">"location"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">

</span><span class="nl">"address"</span><span class="p">:</span><span class="w"> </span><span class="s2">"31 rue saint louis en l'ile, 46 Rue Saint-Louis en l'Île, 75004 Paris, France"</span><span class="p">,</span><span class="w">

</span><span class="nl">"country_code"</span><span class="p">:</span><span class="w"> </span><span class="s2">"FR"</span><span class="p">,</span><span class="w">

</span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Berthillon"</span><span class="w">

</span><span class="p">}</span><span class="w">

</span><span class="p">},</span><span class="w">

</span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Feature"</span><span class="w">

</span><span class="p">},</span><span class="w">

</span><span class="p">{</span><span class="w">

</span><span class="nl">"geometry"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">

</span><span class="nl">"coordinates"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">

</span><span class="mf">28.9777673</span><span class="p">,</span><span class="w">

</span><span class="mf">41.0583419</span><span class="w">

</span><span class="p">],</span><span class="w">

</span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Point"</span><span class="w">

</span><span class="p">},</span><span class="w">

</span><span class="nl">"properties"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">

</span><span class="nl">"date"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2022-02-19T20:03:57Z"</span><span class="p">,</span><span class="w">

</span><span class="nl">"google_maps_url"</span><span class="p">:</span><span class="w"> </span><span class="s2">"http://maps.google.com/?cid=11086473770627030104"</span><span class="p">,</span><span class="w">

</span><span class="nl">"location"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">

</span><span class="nl">"address"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Cumhuriyet Hacıahmet Silahşör Cad, Yeniyol Sk. No:2, 34440 Şişli/İstanbul, Türkiye"</span><span class="p">,</span><span class="w">

</span><span class="nl">"country_code"</span><span class="p">:</span><span class="w"> </span><span class="s2">"TR"</span><span class="p">,</span><span class="w">

</span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"TURK FATIH TUTAK"</span><span class="w">

</span><span class="p">}</span><span class="w">

</span><span class="p">},</span><span class="w">

</span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Feature"</span><span class="w">

</span><span class="p">}</span><span class="w">

</span><span class="p">]</span><span class="w">

</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <p>After downloading the json file I wanted to try out the code that chatgpt provided. To avoid having to setup local environments and to allow other people to run the code, I wanted to run it in Google colab if possible. I asked ChatGPT if it agreed and it said sure and showed me how to start a notebook and upload my “Saved Places.json” file to the directory.</p> <p>I then asked how to start coding and offered this</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">json</span>

<span class="c1"># Load the JSON file
</span><span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">'</span><span class="s">Saved Places.json</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="nb">file</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="nb">file</span><span class="p">)</span>

<span class="c1"># Assuming your JSON has a list of places, adjust the keys as necessary
</span><span class="n">saved_places</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># This will hold tuples of (name, latitude, longitude)
</span><span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>  <span class="c1"># Adjust this loop based on the structure of your JSON file
</span>    <span class="k">try</span><span class="p">:</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">item</span><span class="p">[</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">]</span>  <span class="c1"># Adjust this key based on your JSON structure
</span>        <span class="n">latitude</span> <span class="o">=</span> <span class="n">item</span><span class="p">[</span><span class="sh">'</span><span class="s">geometry</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">location</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">lat</span><span class="sh">'</span><span class="p">]</span>  <span class="c1"># Adjust path as necessary
</span>        <span class="n">longitude</span> <span class="o">=</span> <span class="n">item</span><span class="p">[</span><span class="sh">'</span><span class="s">geometry</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">location</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">lng</span><span class="sh">'</span><span class="p">]</span>  <span class="c1"># Adjust path as necessary
</span>        <span class="n">saved_places</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">name</span><span class="p">,</span> <span class="n">latitude</span><span class="p">,</span> <span class="n">longitude</span><span class="p">))</span>
    <span class="k">except</span> <span class="nb">KeyError</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Key not found in item:</span><span class="sh">"</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>
        <span class="k">continue</span>

<span class="c1"># Print out the first few items to verify
</span><span class="k">for</span> <span class="n">place</span> <span class="ow">in</span> <span class="n">saved_places</span><span class="p">[:</span><span class="mi">5</span><span class="p">]:</span>  <span class="c1"># Print first 5 places to check
</span>    <span class="nf">print</span><span class="p">(</span><span class="n">place</span><span class="p">)</span>
</code></pre></div></div> <p>I ran that and got an error</p> <pre><code class="language----------------------------------------------------------------------------">TypeError                                 Traceback (most recent call last)
&lt;ipython-input-7-8cbb47bb541b&gt; in &lt;cell line: 9&gt;()
      9 for item in data:  # Adjust this loop based on the structure of your JSON file
     10     try:
---&gt; 11         name = item['name']  # Adjust this key based on your JSON structure
     12         latitude = item['geometry']['location']['lat']  # Adjust path as necessary
     13         longitude = item['geometry']['location']['lng']  # Adjust path as necessary

TypeError: string indices must be integers
</code></pre> <p>hm… I can fix this but before I try that I notice the button just below “explain error”. Indulging a digresion into Google colab’s debugging abilities I clicked it and (after agreeing to all terms and conditions) I got a new window explaining the errors and suggesting better code. Huh, not bad!</p> <p>It says try this instead</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">saved_places</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">features</span><span class="sh">'</span><span class="p">]:</span>  <span class="c1"># Adjust this loop based on the structure of your JSON file
</span>    <span class="k">try</span><span class="p">:</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">item</span><span class="p">[</span><span class="sh">'</span><span class="s">properties</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">]</span>  <span class="c1"># Adjust this key based on your JSON structure
</span>        <span class="n">latitude</span> <span class="o">=</span> <span class="n">item</span><span class="p">[</span><span class="sh">'</span><span class="s">geometry</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">coordinates</span><span class="sh">'</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Adjust path as necessary
</span>        <span class="n">longitude</span> <span class="o">=</span> <span class="n">item</span><span class="p">[</span><span class="sh">'</span><span class="s">geometry</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">coordinates</span><span class="sh">'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># Adjust path as necessary
</span>        <span class="n">saved_places</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">name</span><span class="p">,</span> <span class="n">latitude</span><span class="p">,</span> <span class="n">longitude</span><span class="p">))</span>
    <span class="k">except</span> <span class="nb">KeyError</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Key not found in item:</span><span class="sh">"</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>
        <span class="k">continue</span>
</code></pre></div></div> <p>This now outputs</p> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">Key</span><span class="w"> </span><span class="err">not</span><span class="w"> </span><span class="err">found</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">item:</span><span class="w"> </span><span class="p">{</span><span class="err">'geometry':</span><span class="w"> </span><span class="p">{</span><span class="err">'coordinates':</span><span class="w"> </span><span class="p">[</span><span class="mf">2.3567354</span><span class="p">,</span><span class="w"> </span><span class="mf">48.8517232</span><span class="p">],</span><span class="w"> </span><span class="err">'type':</span><span class="w"> </span><span class="err">'Point'</span><span class="p">},</span><span class="w"> </span><span class="err">'properties':</span><span class="w"> </span><span class="p">{</span><span class="err">'date':</span><span class="w"> </span><span class="err">'</span><span class="mi">2022-07-09</span><span class="err">T</span><span class="mi">17</span><span class="err">:</span><span class="mi">15</span><span class="err">:</span><span class="mi">34</span><span class="err">Z'</span><span class="p">,</span><span class="w"> </span><span class="err">'google_maps_url':</span><span class="w"> </span><span class="err">'http://maps.google.com/?cid=</span><span class="mi">3697878718076448074</span><span class="err">'</span><span class="p">,</span><span class="w"> </span><span class="err">'location':</span><span class="w"> </span><span class="p">{</span><span class="err">'address':</span><span class="w"> </span><span class="s2">"31 rue saint louis en l'ile, 46 Rue Saint-Louis en l'Île, 75004 Paris, France"</span><span class="p">,</span><span class="w"> </span><span class="err">'country_code':</span><span class="w"> </span><span class="err">'FR'</span><span class="p">,</span><span class="w"> </span><span class="err">'name':</span><span class="w"> </span><span class="err">'Berthillon'</span><span class="p">}},</span><span class="w"> </span><span class="err">'type':</span><span class="w"> </span><span class="err">'Feature'</span><span class="p">}</span><span class="w">

</span><span class="err">Key</span><span class="w"> </span><span class="err">not</span><span class="w"> </span><span class="err">found</span><span class="w"> </span><span class="err">in</span><span class="w"> </span><span class="err">item:</span><span class="w"> </span><span class="p">{</span><span class="err">'geometry':</span><span class="w"> </span><span class="p">{</span><span class="err">'coordinates':</span><span class="w"> </span><span class="p">[</span><span class="mf">28.9777673</span><span class="p">,</span><span class="w"> </span><span class="mf">41.0583419</span><span class="p">],</span><span class="w"> </span><span class="err">'type':</span><span class="w"> </span><span class="err">'Point'</span><span class="p">},</span><span class="w"> </span><span class="err">'properties':</span><span class="w"> </span><span class="p">{</span><span class="err">'date':</span><span class="w"> </span><span class="err">'</span><span class="mi">2022-02-19</span><span class="err">T</span><span class="mi">20</span><span class="err">:</span><span class="mi">03</span><span class="err">:</span><span class="mi">57</span><span class="err">Z'</span><span class="p">,</span><span class="w"> </span><span class="err">'google_maps_url':</span><span class="w"> </span><span class="err">'http://maps.google.com/?cid=</span><span class="mi">11086473770627030104</span><span class="err">'</span><span class="p">,</span><span class="w"> </span><span class="err">'location':</span><span class="w"> </span><span class="p">{</span><span class="err">'address':</span><span class="w"> </span><span class="err">'Cumhuriyet</span><span class="w"> </span><span class="err">Hacıahmet</span><span class="w"> </span><span class="err">Silahşör</span><span class="w"> </span><span class="err">Cad</span><span class="p">,</span><span class="w"> </span><span class="err">Yeniyol</span><span class="w"> </span><span class="err">Sk.</span><span class="w"> </span><span class="err">No:</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">34440</span><span class="w"> </span><span class="err">Şişli/İstanbul</span><span class="p">,</span><span class="w"> </span><span class="err">Türkiye'</span><span class="p">,</span><span class="w"> </span><span class="err">'country_code':</span><span class="w"> </span><span class="err">'TR'</span><span class="p">,</span><span class="w"> </span><span class="err">'name':</span><span class="w"> </span><span class="err">'TURK</span><span class="w"> </span><span class="err">FATIH</span><span class="w"> </span><span class="err">TUTAK'</span><span class="p">}},</span><span class="w"> </span><span class="err">'type':</span><span class="w"> </span><span class="err">'Feature'</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> <p>Ok let’s fix this and move on. Back to asking ChatGPT:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>User: Let's explore the automated way of adding places, and let's use Google IDs too. Here is what we have so far: 
- a file "saved places.json" 
- a google colab notebook running with access to the file 
- the working script which can read the file and extract info from the json, including name and location
</code></pre></div></div> <p>It returns the following code to get the Google IDs</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">requests</span>
<span class="kn">import</span> <span class="n">json</span>

<span class="c1"># Function to find a place ID given its name and location
</span><span class="k">def</span> <span class="nf">find_place_id</span><span class="p">(</span><span class="n">api_key</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">latitude</span><span class="p">,</span> <span class="n">longitude</span><span class="p">):</span>
    <span class="n">endpoint_url</span> <span class="o">=</span> <span class="sh">"</span><span class="s">https://maps.googleapis.com/maps/api/place/findplacefromtext/json</span><span class="sh">"</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
        <span class="sh">'</span><span class="s">input</span><span class="sh">'</span><span class="p">:</span> <span class="n">name</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">inputtype</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">textquery</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">fields</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">place_id</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">locationbias</span><span class="sh">'</span><span class="p">:</span> <span class="sa">f</span><span class="sh">'</span><span class="s">point:</span><span class="si">{</span><span class="n">latitude</span><span class="si">}</span><span class="s">,</span><span class="si">{</span><span class="n">longitude</span><span class="si">}</span><span class="sh">'</span><span class="p">,</span>
        <span class="sh">'</span><span class="s">key</span><span class="sh">'</span><span class="p">:</span> <span class="n">api_key</span>
    <span class="p">}</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">endpoint_url</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">response</span><span class="p">.</span><span class="nf">json</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">result</span><span class="p">[</span><span class="sh">'</span><span class="s">candidates</span><span class="sh">'</span><span class="p">]:</span>
        <span class="k">return</span> <span class="n">result</span><span class="p">[</span><span class="sh">'</span><span class="s">candidates</span><span class="sh">'</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="sh">'</span><span class="s">place_id</span><span class="sh">'</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">None</span>

<span class="c1"># Your Google API key
</span><span class="n">api_key</span> <span class="o">=</span> <span class="sh">'</span><span class="s">YOUR_API_KEY_HERE</span><span class="sh">'</span>

<span class="c1"># Enhanced loop to include Place IDs
</span><span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="sh">'</span><span class="s">features</span><span class="sh">'</span><span class="p">]:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">item</span><span class="p">[</span><span class="sh">'</span><span class="s">properties</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">location</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">]</span>
        <span class="n">latitude</span> <span class="o">=</span> <span class="n">item</span><span class="p">[</span><span class="sh">'</span><span class="s">geometry</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">coordinates</span><span class="sh">'</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">longitude</span> <span class="o">=</span> <span class="n">item</span><span class="p">[</span><span class="sh">'</span><span class="s">geometry</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">coordinates</span><span class="sh">'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># Find Place ID
</span>        <span class="n">place_id</span> <span class="o">=</span> <span class="nf">find_place_id</span><span class="p">(</span><span class="n">api_key</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">latitude</span><span class="p">,</span> <span class="n">longitude</span><span class="p">)</span>
        <span class="n">saved_places</span><span class="p">.</span><span class="nf">append</span><span class="p">((</span><span class="n">name</span><span class="p">,</span> <span class="n">latitude</span><span class="p">,</span> <span class="n">longitude</span><span class="p">,</span> <span class="n">place_id</span><span class="p">))</span>
    <span class="k">except</span> <span class="nb">KeyError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Key not found </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s"> in item:</span><span class="sh">"</span><span class="p">,</span> <span class="n">item</span><span class="p">)</span>
        <span class="k">continue</span>

<span class="c1"># Print to verify
</span><span class="k">for</span> <span class="n">place</span> <span class="ow">in</span> <span class="n">saved_places</span><span class="p">[:</span><span class="mi">5</span><span class="p">]:</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">place</span><span class="p">)</span>

</code></pre></div></div> <p>Great - but I don’t have a Google API key. I ask how to get it and it guides me through the process. But before we move on, I ask one more thing (I would have used a <code class="language-plaintext highlighter-rouge">.env</code> file but I wanted to ask the question to see what it said):</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>User: OK show me how to secure my API key, so that I can share the code in a safe way
</code></pre></div></div> <p>It gives some good suggestions, including prompting the user for the API key in the code with two lines of code:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">getpass</span> <span class="kn">import</span> <span class="n">getpass</span>
<span class="n">api_key</span> <span class="o">=</span> <span class="nf">getpass</span><span class="p">(</span><span class="sh">'</span><span class="s">Enter your API key:</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>Interesting - hadn’t thought of that. I’ll use the suggestion, I like it more than having to load an environment variable.</p> <p>On to the next step. Automating uploading saved places from a json to a Google account. ChatGPT suggested a manual approach which I am trying to avoid but it’s certainly reasonable. This shows some ability to provide the most reasonable answer first. I asked it for more than one solutions and gave me four solutions:</p> <ol> <li>Manual Addition with Enhanced Support</li> <li>Leverage Google My Maps</li> <li>Use Google Maps API for Custom Applications</li> <li>Share and Collaborate</li> </ol> <p>All four are reasonable and I didn’t think of all four originally. That’s a helpful context to have as I am trying to solve this problem. Let’s pick number 3 and move on. We will try a browser automator tool and specifically we will use Selenium, as ChatGPT suggested. Let’s explore this idea. It provided instructions for doing that including the following snippet.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>### Important Considerations

- **Rate Limiting and Blocking:** Automated interactions can trigger rate limiting or blocking by Google, especially for login and frequent actions. Use delays (`time.sleep()`) to mimic human behavior and reduce the risk of being blocked.
- **Google's Terms of Service:** Ensure your automation respects Google's terms of service. Automating certain actions may violate these terms.
- **Maintainability:** Google Maps' UI can change, which may require you to update your script to match the new structure.

Automating interactions with web services like Google Maps should be approached with caution, respecting usage policies and ethical considerations. For personal use, automation can save time, but ensure your actions don't impact the service's operation for others.
</code></pre></div></div> <p>That’s helpful information which as we will see shortly are an issue. ChatGPT’s ability to provide these potential limitations of this approach up front, while exploring this approach, is certainly helpful context while we are problem solving.</p> <p>In fact, after going through with this solution I ran into two issues:</p> <ul> <li>running selenium in a google colab was not possible</li> <li>selenium cannot work at all for anything that requires google authentication ChatGPT was able to help me explore this solution with helpful snippets of code and with trouble shooting advice. And it was able to tell me about these limitations up front when I was devising a plan.</li> </ul> <p>In the end I ran out of time. By the end of my working session I was not able to create a tool that can transfer a list of saved places from one google account to another. I got stuck at combining browser automation with the need to log in to a google account. I expect this is intentionally hard for security purposes.</p> <p>Nevertheless I learned a lot in the process, including the fact ChatGPT can help us expand our problem solving abilities. I am sure I’ll be coming back to this in the coming weeks.</p> <p>I am starting to think ChatGPT can be to one what Reggie Jeeves is to Bertram Wooster…</p>]]></content><author><name></name></author><category term="llm"/><category term="productivity"/><summary type="html"><![CDATA[Summary I’ve been using ChatGPT for things I know the answer to and it’s working fairly well. I’ve been looking for ways to go further and start using it to explore things I do not know as well. This weekend I had a good excuse to do that.]]></summary></entry><entry><title type="html">Local LLama2+Langchain on a macbook pro</title><link href="https://bayesways.github.io/blog/2023/Local-LLama2-Langchain-on-a-macbook-pro/" rel="alternate" type="text/html" title="Local LLama2+Langchain on a macbook pro"/><published>2023-07-24T00:00:00+00:00</published><updated>2023-07-24T00:00:00+00:00</updated><id>https://bayesways.github.io/blog/2023/Local%20LLama2-Langchain%20on%20a%20macbook%20pro</id><content type="html" xml:base="https://bayesways.github.io/blog/2023/Local-LLama2-Langchain-on-a-macbook-pro/"><![CDATA[<p>In this post I will show how to build a simple LLM chain that runs completely locally on your macbook pro. Will use the latest Llama2 models with Langchain.</p> <h1 id="run-locally-on-your-macbook-pro">Run locally on your Macbook Pro</h1> <p>Create a directory to put all the models and code notebooks in</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir </span>llama2
<span class="nb">cd </span>llama2
</code></pre></div></div> <p>then follow the instructions by <a href="https://blog.lastmileai.dev/run-llama-2-locally-in-7-lines-apple-silicon-mac-c3f46143f327">Suyog Sonwalkar</a> copied here for convenience:</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/ggerganov/llama.cpp.git  
<span class="nb">cd </span>llama.cpp  
curl <span class="nt">-L</span> https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/resolve/main/llama-2-7b-chat.ggmlv3.q4_K_M.bin <span class="nt">--output</span> ./models/llama-2-7b-chat.ggmlv3.q4_K_M.bin   
<span class="nv">LLAMA_METAL</span><span class="o">=</span>1 make
</code></pre></div></div> <p>This will save the local model at the following path (we will need this path later)</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>"llama2/llama.cpp/models/llama-2-7b-chat.ggmlv3.q4_K_M.bin",
</code></pre></div></div> <p>You can test the model works by telling it “recipe for avocado toast”. To do that go to the <code class="language-plaintext highlighter-rouge">llama.cpp</code> directory (if you are not already) and do</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./main <span class="nt">-m</span> ./models/llama-2-7b-chat.ggmlv3.q4_K_M.bin <span class="nt">-n</span> 1024 <span class="nt">-ngl</span> 1 <span class="nt">-p</span> <span class="s2">"recipe for avocado toast"</span>
</code></pre></div></div> <p>You should get something like this:</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>main: build <span class="o">=</span> 893 <span class="o">(</span>4f06592<span class="o">)</span>
main: seed  <span class="o">=</span> 1690215975
llama.cpp: loading model from ./models/llama-2-7b-chat.ggmlv3.q4_K_M.bin
llama_model_load_internal: format     <span class="o">=</span> ggjt v3 <span class="o">(</span>latest<span class="o">)</span>
llama_model_load_internal: n_vocab    <span class="o">=</span> 32000
llama_model_load_internal: n_ctx      <span class="o">=</span> 512
llama_model_load_internal: n_embd     <span class="o">=</span> 4096
llama_model_load_internal: n_mult     <span class="o">=</span> 256
llama_model_load_internal: n_head     <span class="o">=</span> 32
llama_model_load_internal: n_head_kv  <span class="o">=</span> 32
llama_model_load_internal: n_layer    <span class="o">=</span> 32
llama_model_load_internal: n_rot      <span class="o">=</span> 128
llama_model_load_internal: n_gqa      <span class="o">=</span> 1
llama_model_load_internal: n_ff       <span class="o">=</span> 11008
llama_model_load_internal: freq_base  <span class="o">=</span> 10000.0
llama_model_load_internal: freq_scale <span class="o">=</span> 1
llama_model_load_internal: ftype      <span class="o">=</span> 15 <span class="o">(</span>mostly Q4_K - Medium<span class="o">)</span>
llama_model_load_internal: model size <span class="o">=</span> 7B
llama_model_load_internal: ggml ctx size <span class="o">=</span>    0.08 MB
llama_model_load_internal: mem required  <span class="o">=</span> 4193.33 MB <span class="o">(</span>+  256.00 MB per state<span class="o">)</span>
llama_new_context_with_model: kv self size  <span class="o">=</span>  256.00 MB
ggml_metal_init: allocating
ggml_metal_init: using MPS
ggml_metal_init: loading <span class="s1">'/Users/Konstantinosvamvourellis/llama2/llama.cpp/ggml-metal.metal'</span>
ggml_metal_init: loaded kernel_add                            0x107007530
ggml_metal_init: loaded kernel_add_row                        0x107007d60
ggml_metal_init: loaded kernel_mul                            0x107008280
ggml_metal_init: loaded kernel_mul_row                        0x1070088b0
ggml_metal_init: loaded kernel_scale                          0x107008dd0
ggml_metal_init: loaded kernel_silu                           0x1070092f0
ggml_metal_init: loaded kernel_relu                           0x107009810
ggml_metal_init: loaded kernel_gelu                           0x107009d30
ggml_metal_init: loaded kernel_soft_max                       0x10700a3e0
ggml_metal_init: loaded kernel_diag_mask_inf                  0x10700aa40
ggml_metal_init: loaded kernel_get_rows_f16                   0x10700b0c0
ggml_metal_init: loaded kernel_get_rows_q4_0                  0x10700b8b0
ggml_metal_init: loaded kernel_get_rows_q4_1                  0x10700bf30
ggml_metal_init: loaded kernel_get_rows_q2_K                  0x10700c5b0
ggml_metal_init: loaded kernel_get_rows_q3_K                  0x10700cc30
ggml_metal_init: loaded kernel_get_rows_q4_K                  0x10700d2b0
ggml_metal_init: loaded kernel_get_rows_q5_K                  0x10700d930
ggml_metal_init: loaded kernel_get_rows_q6_K                  0x10700dfb0
ggml_metal_init: loaded kernel_rms_norm                       0x10700e670
ggml_metal_init: loaded kernel_norm                           0x10700ee90
ggml_metal_init: loaded kernel_mul_mat_f16_f32                0x10700f6f0
ggml_metal_init: loaded kernel_mul_mat_q4_0_f32               0x10700fdb0
ggml_metal_init: loaded kernel_mul_mat_q4_1_f32               0x107010470
ggml_metal_init: loaded kernel_mul_mat_q2_K_f32               0x107010cb0
ggml_metal_init: loaded kernel_mul_mat_q3_K_f32               0x107011370
ggml_metal_init: loaded kernel_mul_mat_q4_K_f32               0x107011a30
ggml_metal_init: loaded kernel_mul_mat_q5_K_f32               0x1070120d0
ggml_metal_init: loaded kernel_mul_mat_q6_K_f32               0x107012bd0
ggml_metal_init: loaded kernel_rope                           0x1070130f0
ggml_metal_init: loaded kernel_alibi_f32                      0x1070139b0
ggml_metal_init: loaded kernel_cpy_f32_f16                    0x107014240
ggml_metal_init: loaded kernel_cpy_f32_f32                    0x107014ad0
ggml_metal_init: loaded kernel_cpy_f16_f16                    0x107015240
ggml_metal_init: recommendedMaxWorkingSetSize <span class="o">=</span> 10922.67 MB
ggml_metal_init: hasUnifiedMemory             <span class="o">=</span> <span class="nb">true
</span>ggml_metal_init: maxTransferRate              <span class="o">=</span> built-in GPU
llama_new_context_with_model: max tensor size <span class="o">=</span>   102.54 MB
ggml_metal_add_buffer: allocated <span class="s1">'data            '</span> buffer, size <span class="o">=</span>  3891.69 MB, <span class="o">(</span> 3892.14 / 10922.67<span class="o">)</span>
ggml_metal_add_buffer: allocated <span class="s1">'eval            '</span> buffer, size <span class="o">=</span>    10.00 MB, <span class="o">(</span> 3902.14 / 10922.67<span class="o">)</span>
ggml_metal_add_buffer: allocated <span class="s1">'kv              '</span> buffer, size <span class="o">=</span>   258.00 MB, <span class="o">(</span> 4160.14 / 10922.67<span class="o">)</span>
ggml_metal_add_buffer: allocated <span class="s1">'scr0            '</span> buffer, size <span class="o">=</span>   132.00 MB, <span class="o">(</span> 4292.14 / 10922.67<span class="o">)</span>
ggml_metal_add_buffer: allocated <span class="s1">'scr1            '</span> buffer, size <span class="o">=</span>   160.00 MB, <span class="o">(</span> 4452.14 / 10922.67<span class="o">)</span>

system_info: n_threads <span class="o">=</span> 6 / 10 | AVX <span class="o">=</span> 0 | AVX2 <span class="o">=</span> 0 | AVX512 <span class="o">=</span> 0 | AVX512_VBMI <span class="o">=</span> 0 | AVX512_VNNI <span class="o">=</span> 0 | FMA <span class="o">=</span> 0 | NEON <span class="o">=</span> 1 | ARM_FMA <span class="o">=</span> 1 | F16C <span class="o">=</span> 0 | FP16_VA <span class="o">=</span> 1 | WASM_SIMD <span class="o">=</span> 0 | BLAS <span class="o">=</span> 1 | SSE3 <span class="o">=</span> 0 | VSX <span class="o">=</span> 0 |
sampling: repeat_last_n <span class="o">=</span> 64, repeat_penalty <span class="o">=</span> 1.100000, presence_penalty <span class="o">=</span> 0.000000, frequency_penalty <span class="o">=</span> 0.000000, top_k <span class="o">=</span> 40, tfs_z <span class="o">=</span> 1.000000, top_p <span class="o">=</span> 0.950000, typical_p <span class="o">=</span> 1.000000, temp <span class="o">=</span> 0.800000, mirostat <span class="o">=</span> 0, mirostat_lr <span class="o">=</span> 0.100000, mirostat_ent <span class="o">=</span> 5.000000
generate: n_ctx <span class="o">=</span> 512, n_batch <span class="o">=</span> 512, n_predict <span class="o">=</span> 1024, n_keep <span class="o">=</span> 0


 recipe <span class="k">for </span>avocado toast with fresh herbs and lemon

This is a simple and delicious recipe <span class="k">for </span>avocado toast that incorporates fresh herbs and a squeeze of lemon. The addition of the herbs gives the dish a bright, refreshing flavor that complements the richness of the avocado.
Ingredients:

<span class="k">*</span> 2 slices of bread <span class="o">(</span>preferably whole wheat or whole grain<span class="o">)</span>
<span class="k">*</span> 1 ripe avocado, mashed
<span class="k">*</span> Fresh herbs <span class="o">(</span>such as parsley, basil, or cilantro<span class="o">)</span> chopped
<span class="k">*</span> Salt and pepper to taste
<span class="k">*</span> Lemon wedges <span class="o">(</span>optional<span class="o">)</span>
Instructions:

1. Toast the bread <span class="k">until </span>it is lightly browned.
2. Spread the mashed avocado on top of the toasted bread.
3. Sprinkle the chopped fresh herbs over the avocado.
4. Season with salt and pepper to taste.
5. Squeeze a slice of lemon over the avocado toast, <span class="k">if </span>desired.
6. Serve immediately and enjoy!

This recipe is easy to make and can be customized to your liking by using different types of bread or herbs. The lemon adds a <span class="nb">nice </span>tanginess to the dish, but feel free to omit it <span class="k">if </span>you prefer. Enjoy! <span class="o">[</span>end of text]

llama_print_timings:        load <span class="nb">time</span> <span class="o">=</span>  5282.86 ms
llama_print_timings:      sample <span class="nb">time</span> <span class="o">=</span>   200.57 ms /   308 runs   <span class="o">(</span>    0.65 ms per token,  1535.59 tokens per second<span class="o">)</span>
llama_print_timings: prompt <span class="nb">eval time</span> <span class="o">=</span>   637.46 ms /     9 tokens <span class="o">(</span>   70.83 ms per token,    14.12 tokens per second<span class="o">)</span>
llama_print_timings:        <span class="nb">eval time</span> <span class="o">=</span>  9804.24 ms /   307 runs   <span class="o">(</span>   31.94 ms per token,    31.31 tokens per second<span class="o">)</span>
llama_print_timings:       total <span class="nb">time</span> <span class="o">=</span> 10668.64 ms
ggml_metal_free: deallocating
</code></pre></div></div> <p>The model output is this:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> recipe for avocado toast with fresh herbs and lemon

This is a simple and delicious recipe for avocado toast that incorporates fresh herbs and a squeeze of lemon. The addition of the herbs gives the dish a bright, refreshing flavor that complements the richness of the avocado.
Ingredients:

* 2 slices of bread (preferably whole wheat or whole grain)
* 1 ripe avocado, mashed
* Fresh herbs (such as parsley, basil, or cilantro) chopped
* Salt and pepper to taste
* Lemon wedges (optional)
Instructions:

1. Toast the bread until it is lightly browned.
2. Spread the mashed avocado on top of the toasted bread.
3. Sprinkle the chopped fresh herbs over the avocado.
4. Season with salt and pepper to taste.
5. Squeeze a slice of lemon over the avocado toast, if desired.
6. Serve immediately and enjoy!

This recipe is easy to make and can be customized to your liking by using different types of bread or herbs. The lemon adds a nice tanginess to the dish, but feel free to omit it if you prefer. Enjoy! [end of text]
</code></pre></div></div> <p>In this example we installed the LLama2-7B param model for chat. Later I will show how to do the same for the bigger Llama2 models. To see all the LLM model versions that Meta has released on hugging face go <a href="https://huggingface.co/meta-llama">here</a>. Note that to use any of these models from hugging face you’ll need to request approval using this <a href="https://ai.meta.com/resources/models-and-libraries/llama-downloads/">form</a>. You can do that following this <a href="https://twitter.com/jamescalam/status/1682766618831777794?s=61&amp;t=Pw-aY--IwGlNpRBvUW-P9g">demo</a> by James Briggs.</p> <p>To run the model locally though you’ll need the quantized versions of the model (in order to fit within the limitations of your macbook pro). These versions have been made available by <a href="https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/tree/main">TheBloke</a> (based on the work by <a href="https://github.com/ggerganov/llama.cpp">ggerganov</a>), and that’s what we are using here.</p> <h1 id="run-with-langchain">Run with Langchain</h1> <p>To use your local model with Langchain follow the langchain documentation <a href="https://python.langchain.com/docs/use_cases/question_answering/how_to/local_retrieval_qa#llama-v2">here</a>.</p> <p>Note that you’ll need to pass the correct path to your model bin file in the LLamaCpp <code class="language-plaintext highlighter-rouge">model_path</code> param . For me this path was <code class="language-plaintext highlighter-rouge">"../llama.cpp/models/llama-2-7b-chat.ggmlv3.q4_K_M.bin"</code> as shown below:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Make sure the model path is correct for your system!
</span><span class="n">llm</span> <span class="o">=</span> <span class="nc">LlamaCpp</span><span class="p">(</span>
    <span class="n">model_path</span><span class="o">=</span><span class="sh">"</span><span class="s">../llama.cpp/models/llama-2-7b-chat.ggmlv3.q4_K_M.bin</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">n_gpu_layers</span><span class="o">=</span><span class="n">n_gpu_layers</span><span class="p">,</span>
    <span class="n">n_batch</span><span class="o">=</span><span class="n">n_batch</span><span class="p">,</span>
    <span class="n">n_ctx</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
    <span class="n">f16_kv</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>  <span class="c1"># MUST set to True, otherwise you will run into problem after a couple of calls
</span>    <span class="n">callback_manager</span><span class="o">=</span><span class="n">callback_manager</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></div> <h1 id="running-other-llama-model-versions">Running other LLama model versions</h1> <p>LLama has released different versions of the models, as discussed. However to run them locally you’ll need the quantized versions provided by independent developers such as <a href="https://huggingface.co/TheBloke">TheBloke</a>.</p> <p>To download other versions you’ll need to</p> <ul> <li>find the appropriate quantized version you’ll need, for example go <a href="https://huggingface.co/TheBloke/Llama-2-70B-GGML">here</a> for the 70B param GGML model version</li> <li>adjust the names of the models in the commands used, for example replace <code class="language-plaintext highlighter-rouge">llama-2-7b-chat.ggmlv3.q4_K_M.bin</code> with <code class="language-plaintext highlighter-rouge">llama-2-70b.ggmlv3.q4_0.bin</code></li> </ul> <p>For example, I was able to install the 13B chat version and ran it successfully. To do that and test that it works go to the <code class="language-plaintext highlighter-rouge">llama.cpp</code> directory (if you are not already) and do</p> <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
curl <span class="nt">-L</span> https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML/resolve/main/llama-2-13b-chat.ggmlv3.q4_0.bin <span class="nt">--output</span> ./models/llama-2-13b-chat.ggmlv3.q4_0.bin   
<span class="nv">LLAMA_METAL</span><span class="o">=</span>1 make
./main <span class="nt">-m</span> ./models/llama-2-13b-chat.ggmlv3.q4_0.bin <span class="nt">-n</span> 1024 <span class="nt">-ngl</span> 1 <span class="nt">-p</span> <span class="s2">"recipe for avocado toast"</span>
</code></pre></div></div> <h1 id="performance">Performance</h1> <p>I was able to run the 7B chat version model on my machine - see this <a href="https://github.com/bayesways/local_llama2_demo">repo</a> for my setup. I ran it on a Macbook pro with an M2 Pro chip 16G RAM and it took ~1-2 seconds to generate the response. The performance you’ll experience will be a function of the parameters used. To see all the parameters go to <code class="language-plaintext highlighter-rouge">llama.cpp</code> directory and do</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./main --help
</code></pre></div></div> <p>I found performance to be sensitive to the context size (<code class="language-plaintext highlighter-rouge">--ctx-size</code> in terminal, <code class="language-plaintext highlighter-rouge">n_ctx</code> in langchain) in Langchain but less so in the terminal. If you are getting a slow response try lowering the context size <code class="language-plaintext highlighter-rouge">n_ctx</code>.</p> <p>Here are the performance metadata from the terminal calls for the two models:</p> <p>Performance of the 7B model:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>llama_print_timings:        load time =  4910.88 ms
llama_print_timings:      sample time =   154.19 ms /   236 runs   (    0.65 ms per token,  1530.57 tokens per second)
llama_print_timings: prompt eval time =   491.16 ms /     9 tokens (   54.57 ms per token,    18.32 tokens per second)
llama_print_timings:        eval time =  7490.65 ms /   235 runs   (   31.88 ms per token,    31.37 tokens per second)
llama_print_timings:       total time =  8155.16 ms
</code></pre></div></div> <p>Performance of the 13B model:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>llama_print_timings:        load time =  8227.97 ms
llama_print_timings:      sample time =   331.46 ms /   506 runs   (    0.66 ms per token,  1526.60 tokens per second)
llama_print_timings: prompt eval time =  8755.93 ms /   266 tokens (   32.92 ms per token,    30.38 tokens per second)
llama_print_timings:        eval time = 28269.76 ms /   504 runs   (   56.09 ms per token,    17.83 tokens per second)
llama_print_timings:       total time = 37405.66 ms
</code></pre></div></div> <h1 id="run-online-in-google-colabhugging-face">Run Online in Google Colab+Hugging Face</h1> <p>If you don’t have a macbook with a M2 chip or want faster performance you can run llama2 with langchain in a google colab <a href="https://github.com/bayesways/local_llama2_demo/blob/main/llama_2_13b_chat_agent.ipynb">notebook</a>. I’ve taken the instructions from this <a href="https://twitter.com/jamescalam/status/1682766618831777794?s=61&amp;t=Pw-aY--IwGlNpRBvUW-P9g">demo</a> by James Briggs and simplified. The notebook runs from start to finish in ~ 10 mins.</p> <p>Since we are using Google Colab the model is running on the GPUs that Google makes available as part of the Colab service. I found that 13b parameter Llama2 model runs fast and stays within the GPU memory limits of the free Colab version. The 70B parameter is worth trying but you might need to upgrade the resources and with a paid subscription for that. We also make use of the the Hugging face pipeline from Langchain which allows to run any model published in Hugging Face, which makes for more general code, but for that you will need any API key.</p> <p>The setup you need is as follows:</p> <ul> <li>Hugging face api key</li> <li>Save the Hugging face api key in a file <code class="language-plaintext highlighter-rouge">secret_api_keys.env</code> which you’ll save in your top directory of the google drive.</li> <li>To apply to use LLama2 and get approved (go <a href="https://ai.meta.com/resources/models-and-libraries/llama-downloads/">here</a> and register with an email same as the one in your hugging face account)</li> <li>Hugging face to match your Meta approval with your Hugging face email</li> </ul> <h2 id="references">References</h2> <ul> <li>Llama2+Langchain <a href="https://twitter.com/jamescalam/status/1682766618831777794?s=61&amp;t=Pw-aY--IwGlNpRBvUW-P9g">demo</a> by James Briggs</li> <li>Run LLama2 on macbook pro based on three similar instructions by <a href="https://twitter.com/AdrienBrault/status/1681503574814081025">Adrien Brault</a>, <a href="https://blog.lastmileai.dev/run-llama-2-locally-in-7-lines-apple-silicon-mac-c3f46143f327">Suyog Sonwalkar</a> or <a href="https://www.youtube.com/watch?v=Kg588OVYTiw">Abhishek Thakur</a></li> <li>Langchain <a href="https://python.langchain.com/docs/use_cases/question_answering/local_retrieval_qa">documentation</a> for locally run models</li> </ul>]]></content><author><name></name></author><category term="llm"/><summary type="html"><![CDATA[In this post I will show how to build a simple LLM chain that runs completely locally on your macbook pro. Will use the latest Llama2 models with Langchain.]]></summary></entry><entry><title type="html">Track your goals with Obsidian</title><link href="https://bayesways.github.io/blog/2023/goal-tracker-obsidian/" rel="alternate" type="text/html" title="Track your goals with Obsidian"/><published>2023-06-08T00:00:00+00:00</published><updated>2023-06-08T00:00:00+00:00</updated><id>https://bayesways.github.io/blog/2023/goal-tracker-obsidian</id><content type="html" xml:base="https://bayesways.github.io/blog/2023/goal-tracker-obsidian/"><![CDATA[<p>This blog post presents how I got started setting up my goal tracking process using Obsidian and a few amazing plugins. At a later post I may come back to assess how it worked.</p> <h1 id="motivation">Motivation</h1> <p>As someone who struggles to stick to one thing, I’ve been looking for a tool to help me set and track goals. I’ve been using Obsidian for a month to keep notes on various interests of mine. It has been a very helpful so far, so I started looking for ways to organize my checklists and tasks with it as well. I am already running a checklist for the week and a general check list for things I am curious about. However I found that the weekly checklist was inadequate for my needs. I needed something to actually organize my time at the micro level (hour or day) and to connect it to macro goals (monthly or even yearly). Simply having a weekly priority list didn’t cut it.</p> <h1 id="daily-and-weekly-notes">Daily and weekly notes</h1> <p>I was inspired by <a href="https://nicolevanderhoeven.com/">Nicole van der Hoeven</a> to use Obsidian for goal tracking. Her youtube channel and blog contains many useful processes for increasing your productivity in general. After browsing the materials on her website I decided to try set up a system, heavily based on her suggestions.</p> <p>First I installed the <a href="https://github.com/liamcain/obsidian-calendar-plugin">Calendar plugin</a> which is perfect for daily logs. But if you pair it with another plugin called <a href="https://github.com/liamcain/obsidian-periodic-notes">Periodic notes</a> you can go beyond daily to weekly/monthly etc. That’s what I am interested in, so that I can connect my daily work to my larger monthly goals all the way to the yearly if needed.</p> <p>Here are the basic steps :</p> <ol> <li>create a daily notes template(more on this in a minute) to help me organize my work at the lowest level possible, the day. This is something I didn’t have before so I hope to provide me with the structure I need.</li> <li>create a weekly template to replace my current weekly checklist notes.</li> <li>put all the templates in my templates folder.</li> <li>create a reviews folder with daily and weekly subfolders to save all of the notes I intend to create.</li> <li>install Periodic notes and set the appropriate paths in the settings of the plugin</li> <li>Set the appropriate template-folder pairs in the settings of the <a href="https://github.com/SilentVoid13/Templater">Templater plugin</a> (if you don’t use it I recommend checking it out).</li> </ol> <h1 id="effective-templates">Effective templates</h1> <p>To create effective templates I start from one recommended by others and try to understand what it does by breaking it down. This way I can keep only the bits that work for me.</p> <p>As I worked with the daily note template I realized that there are basically three things I needed.</p> <ul> <li>a daily log, a place to brain dump with no regrets :)</li> <li>a list of tasks I need to finish to keep me on track</li> <li>a way to connect these tasks to the long term goals</li> </ul> <p>Here is the daily template I landed on (after 2-3 days of experimenting):</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## Direction
This is what you are working towards!

![[reviews/weekly/Weekly Review 2023-W23#This week]]

## Task due today

# Log

### Tomorrow, I need to ...

</code></pre></div></div> <ul> <li>Direction: this pulls in the goals I’ve set for the week (more on this below)</li> <li>Task due today: is a checklist that I create manually</li> <li>Tomorrow I need to: prepare checklist for tomorrow’s note</li> <li>Log: brain dump area</li> </ul> <p>The following part uses the <a href="https://github.com/blacksmithgu/obsidian-dataview">Dataview plugin</a> which is an extremely powerful tool. Here I am doing a simple query from the weekly note to pull in the goals of the week and present them in my daily note.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>![[reviews/weekly/Weekly Review 2023-W23#This week]]
</code></pre></div></div> <p>For the weekly note I needed three things:</p> <ul> <li>goals for the week</li> <li>and end of week checklist for things that need to happen every week</li> <li>a space to reflect on the week and jot down lessons for the next week</li> <li>A way to connect the weekly goals to the monthly level (more on this later)</li> </ul> <p>Here is the weekly template I went with (after some tinkering again):</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt; [!warning] No more than 3 !
&gt; If you could only get three specific goals done this week, what would they be? 
## This week
- [ ] 

## Monthly initiatives

Keep these things in mind as you do this week's review:

## Monthly review 2023-M06 

[[reviews/monthly/Monthly Review 2023-M06#This month]]


## Reflections for the week 
&gt; [!question]
&gt; Did you finish all of last weeks items?


## End-of-week-checklist

- [ ] review events for the week
- [ ] backup computer
</code></pre></div></div> <p>You notice the pattern. A place to keep organized on the daily level but connect it to the level above too. Then at the weekly level a place to keep organized and connect it to the level above. And so on.</p> <p>For now to connect the levels all I do is to list the goals of the levels above within the note for the tasks below. I will come back to this and reassess if this is sufficient or not, but in these few days I’ve been using it’s working fine.</p> <p>One final note on templates. I found that using the <a href="https://help.obsidian.md/Editing+and+formatting/Callouts">Callouts functions</a> to create visual warnings help me write better goals.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt; [!warning] No more than 3 !
&gt; If you could only get three specific goals done this week, what would they be? 
</code></pre></div></div> <h1 id="okrs-for-the-quarter">OKRs for the quarter</h1> <p>Most goals or tasks take a little bit of time, say a couple of hours. But some of my learning goals, such as learning a programming language, can span months. For such goals, I am writing them down as quarterly goals and then creating monthly initiatives to help me achieve these goals. The initiatives are intended to be as factual as possible, the technical term being OKRs. It seems a little formal to track goals this way. But I’ve never found an effective way to track such long term goals, so I am willing to give the OKR method a try. For a more detailed description you can see this <a href="https://marcus.se.net/how-i-set-and-track-goals-in-obsidian/">post</a> by Marcus Ollson.</p> <p>Again following the same idea as above, I embed the monthly initiatives in the weekly notes, and the quarterly goals in the monthly review notes. I did not see the need to plan the year yet, so I stopped at the quarter. Nicole goes into more details in her <a href="https://www.youtube.com/watch?v=T2Aeaq4sk7M">video</a> which is very helpful.</p> <p>For now I will stick with the simple methods I described above but I will revisit this post to assess it.</p>]]></content><author><name></name></author><category term="productivity"/><category term="obsidian"/><category term="plugins"/><summary type="html"><![CDATA[This blog post presents how I got started setting up my goal tracking process using Obsidian and a few amazing plugins. At a later post I may come back to assess how it worked.]]></summary></entry><entry><title type="html">How to get started with LLM App building and Langchain? Part 2 of n</title><link href="https://bayesways.github.io/blog/2023/LLM-apps-p2/" rel="alternate" type="text/html" title="How to get started with LLM App building and Langchain? Part 2 of n"/><published>2023-05-16T00:00:00+00:00</published><updated>2023-05-16T00:00:00+00:00</updated><id>https://bayesways.github.io/blog/2023/LLM-apps-p2</id><content type="html" xml:base="https://bayesways.github.io/blog/2023/LLM-apps-p2/"><![CDATA[<h1 id="overview">Overview</h1> <p>In <a href="https://bayesways.github.io/blog/2023/How-to-get-started-with-LLM-App-building-and-Langchain-Part-1-of-n/">Part 1 of n</a> we got a general overview of the Langchain framework for building LLM apps. We are now going deeper into some of the issues we will face as we start building our app. As a reminder, our goal is to build an app that can answer questions on a personal library of information, and provide citations for its answers. The fancy term for this is <em>retrieval augmented generation</em>. The high level structure of a chain appropriate for this task is described in <a href="https://docs.langchain.com/docs/use-cases/qa-docs">this</a> use case from the Langchain documentation. I am copying it here directly from the docs:</p> <p><strong>Ingestion</strong> In order use a language model to interact with your data, you first have to get in a suitable format. That format would be an <code class="language-plaintext highlighter-rouge">Index</code>. By putting data into an Index, you make it easy for any downstream steps to interact with it.</p> <p>There are several types of indexes, but by far the most common one is a Vectorstore. Ingesting documents into a vectorstore can be done with the following steps:</p> <ol> <li>Load documents (using a Document Loader)</li> <li>Split documents (using a Text Splitter)</li> <li>Create embeddings for documents (using a Text Embedding Model)</li> <li>Store documents and embeddings in a vectorstore</li> </ol> <p><strong>Generation</strong> Now that we have an Index, how do we use this to do generation? This can be broken into the following steps:</p> <ol> <li>Receive user question</li> <li>Lookup documents in the index relevant to the question</li> <li>Construct a PromptValue from the question and any relevant documents (using a PromptTemplate).</li> <li>Pass the PromptValue to a model</li> <li>Get back the result and return to the user.</li> </ol> <h1 id="implementation">Implementation</h1> <p>We will use python so let’s go to the documentation <a href="https://python.langchain.com/en/latest/use_cases/question_answering.html">page</a> for this use case from Langchain. This doc provides a quick start where the <em>ingestion</em> and <em>generation</em> parts are all combined together. Later on we will break it down to understand the components one by one. But first let’s see the big picture.</p> <p>Note that the document we use here is the State of the Union Address, so we need to first create a txt file containing the text in question and save in <code class="language-plaintext highlighter-rouge">../docs/state_of_the_union.txt</code> - copy past from <a href="https://www.whitehouse.gov/state-of-the-union-2023/">here</a>. The firefox read mode comes handy to give us the pure text without the extra stuff on the page. If you want a clean version to play with you can find an older state of the union address text file <a href="https://github.com/hwchase17/langchain/blob/master/docs/modules/state_of_the_union.txt">here</a>. If you use the latter, modify your query below to ask a question relevant to that text.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># requires: pip install openai langchain chromadb 
</span><span class="kn">import</span> <span class="n">os</span>
<span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="sh">'</span><span class="s">OPENAI_API_KEY</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="o">&lt;</span><span class="n">your_api_key</span><span class="o">&gt;</span>

<span class="kn">from</span> <span class="n">langchain.document_loaders</span> <span class="kn">import</span> <span class="n">TextLoader</span>
<span class="n">loader</span> <span class="o">=</span> <span class="nc">TextLoader</span><span class="p">(</span><span class="sh">'</span><span class="s">../docs/state_of_the_union.txt</span><span class="sh">'</span><span class="p">)</span>
  
<span class="kn">from</span> <span class="n">langchain.indexes</span> <span class="kn">import</span> <span class="n">VectorstoreIndexCreator</span>
<span class="n">qa_index</span> <span class="o">=</span> <span class="nc">VectorstoreIndexCreator</span><span class="p">().</span><span class="nf">from_loaders</span><span class="p">([</span><span class="n">loader</span><span class="p">])</span>
</code></pre></div></div> <p>We will ask a question about a topic from the text. The president said the following (quoting from the text):</p> <blockquote> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>For example, I — I should have known this, but I didn’t until two years ago: Thirty million workers have to sign non-compete agreements for the jobs they take. Thirty million. So a cashier at a burger place can’t walk across town and take the same job at another burger place and make a few bucks more.
</code></pre></div> </div> </blockquote> <p>Let’s ask the bot a question about it.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">query</span> <span class="o">=</span> <span class="sh">"</span><span class="s">What did the president say about non-compete agreements?</span><span class="sh">"</span>
<span class="n">qa_index</span><span class="p">.</span><span class="nf">query</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
</code></pre></div></div> <p>The response:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>" The president said that they have banned non-compete agreements so companies have to compete for workers and pay them what they're worth."
</code></pre></div></div> <p>A pretty reasonable response.</p> <p>Let’s see what’s going on under the hood - have been waiting to say this.</p> <h1 id="implementation-break-down">Implementation break down</h1> <h3 id="ingestion">Ingestion</h3> <p>We first address the <strong>ingestion</strong> part of the steps. This means preparing the structure around the documents that we want to use when a user asks a question. The outcome of this part is a vector database, that we can pass to a chain during the <strong>generation</strong> part.</p> <h4 id="vectorindex">VectorIndex</h4> <p>The key functionality we need to understand is the <code class="language-plaintext highlighter-rouge">VectorstoreIndexCreator</code>, and specifically the following command.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">VectorstoreIndexCreator</span><span class="p">().</span><span class="nf">from_loaders</span><span class="p">([</span><span class="n">loader</span><span class="p">])</span>
</code></pre></div></div> <p>What this does is the following:</p> <ol> <li>split the text in chunks (we will discuss the specifics but it doesn’t matter to much</li> <li>specify the LLM model which we will use to compute the embeddings (vector values assigned to each chunk)</li> <li>create a database where we store the vectors, we will use <code class="language-plaintext highlighter-rouge">Chroma</code></li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 1
</span><span class="n">documents</span> <span class="o">=</span> <span class="n">loader</span><span class="p">.</span><span class="nf">load</span><span class="p">()</span>
<span class="kn">from</span> <span class="n">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">CharacterTextSplitter</span>
<span class="n">text_splitter</span> <span class="o">=</span> <span class="nc">CharacterTextSplitter</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">texts</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="p">.</span><span class="nf">split_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>

<span class="c1"># 2
</span><span class="kn">from</span> <span class="n">langchain.embeddings</span> <span class="kn">import</span> <span class="n">OpenAIEmbeddings</span>
<span class="n">embeddings</span> <span class="o">=</span> <span class="nc">OpenAIEmbeddings</span><span class="p">()</span>

<span class="c1"># 3
</span><span class="kn">from</span> <span class="n">langchain.vectorstores</span> <span class="kn">import</span> <span class="n">Chroma</span>
<span class="n">db</span> <span class="o">=</span> <span class="n">Chroma</span><span class="p">.</span><span class="nf">from_documents</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">embeddings</span><span class="p">)</span>
<span class="n">retriever</span> <span class="o">=</span> <span class="n">db</span><span class="p">.</span><span class="nf">as_retriever</span><span class="p">()</span>
</code></pre></div></div> <p>If we want to preview the <strong>generation</strong> part we can add a fourth step</p> <ol> <li>create a chain that uses the vectors to answer questions</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># 4
</span><span class="n">qa_index</span> <span class="o">=</span> <span class="n">RetrievalQA</span><span class="p">.</span><span class="nf">from_chain_type</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="nc">OpenAI</span><span class="p">(),</span> <span class="n">chain_type</span><span class="o">=</span><span class="sh">"</span><span class="s">stuff</span><span class="sh">"</span><span class="p">,</span> <span class="n">retriever</span><span class="o">=</span><span class="n">retriever</span><span class="p">)</span>

<span class="n">qa_index</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">query</span><span class="p">)</span> <span class="c1">#same query as before
</span></code></pre></div></div> <h2 id="generation">Generation</h2> <p>Once we have our vector database we can use it for various tasks, aka create different kinds of chains.</p> <h4 id="retrieve-relevant-documents">Retrieve relevant documents</h4> <p>The simplest thing we can do is to retrieve a list of relevant documents to a specific query. The following code will return 4 documents, i.e. text chunks, ordered by relevance to the query we made.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">docsearch</span> <span class="o">=</span> <span class="n">db</span><span class="p">.</span><span class="nf">as_retriever</span><span class="p">()</span>
<span class="n">query</span> <span class="o">=</span> <span class="sh">"</span><span class="s">What did the president say about non-compete agreements?</span><span class="sh">"</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">docsearch</span><span class="p">.</span><span class="nf">get_relevant_documents</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
</code></pre></div></div> <h4 id="ask-questions-based-on-the-documents">Ask questions based on the documents</h4> <p>Once we have our docs, we can ask questions on them with a simple LLM chain, which is made easy using the <code class="language-plaintext highlighter-rouge">load_qa_chain</code> template.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">langchain.chains.question_answering</span> <span class="kn">import</span> <span class="n">load_qa_chain</span>
<span class="kn">from</span> <span class="n">langchain.llms.openai</span> <span class="kn">import</span> <span class="n">OpenAI</span>

<span class="n">chain</span> <span class="o">=</span> <span class="nf">load_qa_chain</span><span class="p">(</span><span class="n">llm</span><span class="o">=</span><span class="nc">OpenAI</span><span class="p">(),</span> <span class="n">chain_type</span><span class="o">=</span><span class="sh">"</span><span class="s">stuff</span><span class="sh">"</span><span class="p">)</span>
<span class="n">query</span> <span class="o">=</span> <span class="sh">"</span><span class="s">What did the president say about non-compete agreements?</span><span class="sh">"</span>
<span class="n">chain</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">input_documents</span><span class="o">=</span><span class="n">docs</span><span class="p">,</span> <span class="n">question</span><span class="o">=</span><span class="n">query</span><span class="p">)</span>
</code></pre></div></div> <p>From here on we can use the docs we retrieved as we like and combine it with other chains. The most common use case is passing the docs as part of the prompt input, called <em>context</em>, and asking the bot to answer using this context. See more examples <a href="https://python.langchain.com/en/latest/modules/chains/index_examples/qa_with_sources.html">here</a></p> <h2 id="references">References</h2> <ul> <li>Langchain <a href="https://python.langchain.com/en/latest/use_cases/question_answering.html">overview</a> of question and answering with sources</li> <li>Langchain <a href="https://python.langchain.com/en/latest/modules/indexes/getting_started.html">docs</a> for Indexes.</li> <li>Examples of</li> </ul>]]></content><author><name></name></author><category term="llm"/><summary type="html"><![CDATA[Overview]]></summary></entry><entry><title type="html">How to get started with LLM App building and Langchain? Part 1 of n</title><link href="https://bayesways.github.io/blog/2023/LLM-apps-p1/" rel="alternate" type="text/html" title="How to get started with LLM App building and Langchain? Part 1 of n"/><published>2023-05-15T00:00:00+00:00</published><updated>2023-05-15T00:00:00+00:00</updated><id>https://bayesways.github.io/blog/2023/LLM-apps-p1</id><content type="html" xml:base="https://bayesways.github.io/blog/2023/LLM-apps-p1/"><![CDATA[<p>I will use this space to document my effort to build LLM applications, starting pretty much from scratch. In order to have a concrete goal, I will aim to understand how to build an app that can answer questions and provide citations, utilizing a personal library of information. However, the lessons will apply equally to other use cases, some of which are listed in the references.</p> <h2 id="background">Background</h2> <p>It goes without saying that any LLM application is going to be based on <strong>Langchain</strong>. The <a href="https://docs.langchain.com/docs/">conceptual guide</a> is a good place to start.</p> <p>LLMs are game changing, partly because, they can simulate semantic understanding. This means that they can perform tasks that would typically require someone to understand the meaning of text, even if they don’t really “understand” the text. Text is an example of an unstructured data format, as opposed to a structured dataset such as a database for example. Querying a database is simple because the data is stored in a way that’s optimized for querying. Text on the other hand is words on a page without any pre-specified structure imposed on them. One can (correctly) object this point as human language is in fact at least partially structured, otherwise any random set of words would be meaningful. However for data retrieval purposes, a newspaper article is highly unstructured compared to a database. LLMs fill the gap and make retrieving information from unstructured text data possible, performing at the level we would expect someone with human language understanding to perform.</p> <p>The way LLM applications impose “structure” on text is via indexes (see the conceptual documentation <a href="https://docs.langchain.com/docs/components/indexing/">here</a>). These are emerging specialized data structures to facilitate LLM application building. Currently the main type of index used is a <em>vector databases</em> which stores <em>embeddings</em>, a numerical vector associated with a chunk of text.</p> <h2 id="basic-elements-of-langchain">Basic Elements of Langchain</h2> <h3 id="models">Models</h3> <p>Three kinds of models (quoting directly the documentation <a href="https://docs.langchain.com/docs/components/models/">page</a>)</p> <ul> <li>Large Language Models (LLMs) are the first type of models we cover. These models take a text string as input, and return a text string as output.</li> <li>Chat Models are the second type of models we cover. These models are usually backed by a language model, but their APIs are more structured. Specifically, these models take a list of Chat Messages as input, and return a Chat Message.</li> <li>Text Embedding Models. These models take text as input and return a list of floats.</li> </ul> <h3 id="inputoutput">Input/Output</h3> <p>Any LLM output can be post-processed to fit specific requirements. Langchain provides the specialized output parsers for this reason (see <a href="https://docs.langchain.com/docs/components/prompts/output-parser">here</a>)</p> <h3 id="indexes">Indexes</h3> <p>The database structure needed to facilitate LLM building. As we mentioned above, LLM applications building requires us to put some structure around text and store it, aka <em>index</em> text data. To do that Langchain provides specialized tools and integrates with the providers of such vector databases, such as <code class="language-plaintext highlighter-rouge">pinecone</code> and <code class="language-plaintext highlighter-rouge">chroma</code>. Note that to create a text embedding, typically we need to use a pre-trained LLM.</p> <h3 id="memory">Memory</h3> <p>Referes to the memory used by a chat agent. It’s important to distinguish between short and long memory. <em>Short memory</em> captures the context of a singular conversation with an agent, whereas <em>long memory</em> refers to the rest of information that persists between conversations. The main concrete example of memory usage is for storing the context of a conversation between a user and a chatbot, and expanding that context as the conversation evolves. Langchain provides tools to handle this scenario.</p> <h3 id="chains">Chains</h3> <p>Chain is the name given to an object that captures smaller components pieced together. The main type of a chain is an <strong>LLM-Chain</strong> which typically contains three components:</p> <ul> <li>an LLM model (such as <a href="https://platform.openai.com/docs/models/gpt-3">GPT3</a> or <a href="https://ai.googleblog.com/2021/10/introducing-flan-more-generalizable.html">Flan</a>)</li> <li>a prompting template</li> <li>an output parser Each component might be broken down into further specialized pieces to achieve the desired goal of the application.</li> </ul> <p>The other common type of chain is an <strong>Index-related chain</strong> which uses the power of an LLM to interact with a specific text that the user chooses. The simplest way to pass the text to the LLM is to “stuff” it in the prompt of an LLM-Chain, hence defaulting back to the framework described above. However, that’s not always the best choice and Langchain provides some additional methods for interacting with (indexed) text using LLMs.</p> <h3 id="prompting">Prompting</h3> <p>Prompting refers to the text input given to an LLM or chat agent. Although it might sound simple, it is a vital piece of LLM app building. Langchain provides some frameworks for selecting the “right” prompt depending on the use case. The general task of prompting is more general, so we will have to come back to this.</p> <h3 id="agents">Agents</h3> <p>This refers to chains that do not have a pre-determined order of components. Instead, these chains consists of an “agent” and a pre-determined list of tools. The user interacts with the “agent” which has access to a suite of tools, and it’s up to the “agent” to decide what tool to use when, depending on the user input. We will leave this for a next post.</p> <h2 id="references">References</h2> <ul> <li><a href="https://docs.langchain.com/docs/">Conceptual guide to langchain</a></li> <li><a href="https://docs.langchain.com/docs/category/use-cases">List of LLM use cases</a></li> </ul>]]></content><author><name></name></author><category term="llm"/><summary type="html"><![CDATA[I will use this space to document my effort to build LLM applications, starting pretty much from scratch. In order to have a concrete goal, I will aim to understand how to build an app that can answer questions and provide citations, utilizing a personal library of information. However, the lessons will apply equally to other use cases, some of which are listed in the references.]]></summary></entry><entry><title type="html">Obsessed with Obsidian</title><link href="https://bayesways.github.io/blog/2023/Obsidian/" rel="alternate" type="text/html" title="Obsessed with Obsidian"/><published>2023-05-11T00:00:00+00:00</published><updated>2023-05-11T00:00:00+00:00</updated><id>https://bayesways.github.io/blog/2023/Obsidian</id><content type="html" xml:base="https://bayesways.github.io/blog/2023/Obsidian/"><![CDATA[<h2 id="overview">Overview</h2> <p>Obsidian is a note organizer. I have been using the very basic features for a few months but only recently delved deeper. It’s been game changing. In this post I will lay out a quick list of the resources I used to learn.</p> <p>For someone who likes to keep notes <em>and</em> revisit them, Obsidian can be extremely pleasing to use. Having a blog is a good alternative but Obsidian differs in a couple of fundamental reasons:</p> <ul> <li>it’s easy to use and aesthetically pleasing</li> <li>it allows for seamless linking between notes</li> <li>it’s as simple or as complex as the user desires</li> </ul> <p>I think the best way to describe it is a <em>personal notebook interface</em>.</p> <p>I started using Obsidian to keep random tabs on ideas. Then I started linking them leaving placeholders for anything I meant to follow up on. I started treating it as a digital addendum to my physical notebook, creating notes for anything digital I wanted to keep for future reference. Soon enough I had a list of notes containing coding snippets, articles, quotes, video links, recipes, and instructions. Then I started using it as a todo list as well. But more recently I discovered how to use it a productivity booster in everything else I do. Here are some use cases:</p> <h4 id="write-blog-posts">Write blog posts</h4> <p>Be able to create a blog post using a template. Use the <strong>templater plugin</strong>.</p> <h4 id="meeting-notes">Meeting Notes</h4> <p>Create notes for meetings and be able to search them later. This could be achieved by logging notes with <strong>tags</strong>, or by using <strong>metadata</strong>. If use tags make sure to use <strong>tag-wrangler plugin</strong> Can also sync it up to a calendar plugin to keep all notes organized and connected to a calendar.</p> <p>Later on I can create a note that retrieves information from the meetings with the <strong>datataview plugin</strong>.</p> <h4 id="special-events">Special Events</h4> <p>Connect notes to a special physical event so you can find later This could be notes from a special event like a workshop or a hackathon. Can use a special tag for this.</p> <h4 id="learning">Learning</h4> <p>Organize notes as I learn something new. Connect and refactor as I go along.</p> <ul> <li>Note new things that are interesting</li> <li>come back to connect them to existing notes</li> </ul> <p>Organizing them in a concise manner would be a learning goal, but also could be shared on the web using <strong>Obsidian Publish</strong> if one wishes to “learn in public”.</p> <h4 id="keep-notes-from-interesting-meetings">Keep notes from interesting meetings</h4> <p>Keep notes from meeting and connect them to profiles and other notes. See this <a href="https://www.youtube.com/watch?v=5j9fAvJCaig">video</a> for a great example of how to organize meetings and profiles using <strong>templater plugin</strong> and <strong>datataview plugin</strong>.</p> <h2 id="resources">Resources</h2> <p><a href="https://nicolevanderhoeven.com/">Nicole van der Hoeven</a> has a ton of excellent resources on Obsidian, such as this <a href="https://www.youtube.com/watch?v=5j9fAvJCaig">video</a></p> <p><a href="https://www.youtube.com/@linkingyourthinking">Linkingyourthinking</a> is a great youtube channel with a lot of good info as well.</p>]]></content><author><name></name></author><category term="productivity"/><category term="obsidian"/><category term="plugins"/><summary type="html"><![CDATA[Overview]]></summary></entry><entry><title type="html">Setting up a new computer</title><link href="https://bayesways.github.io/blog/2023/setting-up-a-new-computer/" rel="alternate" type="text/html" title="Setting up a new computer"/><published>2023-04-30T00:00:00+00:00</published><updated>2023-04-30T00:00:00+00:00</updated><id>https://bayesways.github.io/blog/2023/setting-up-a-new-computer</id><content type="html" xml:base="https://bayesways.github.io/blog/2023/setting-up-a-new-computer/"><![CDATA[<p>This is a post for mostly personal use (more than my personal average :) ). Having to set up a new laptop is one of those events that fall in the optimal postponing zone. Happens regularly to annoy you but infrequently to justify solving it systematically. So you only remember it when it happens and you put off solving it for another few years because “why spend extra time on it now?”.</p> <p>I just got a new laptop so I am going to document the steps it takes me to set it up.</p> <h2 id="basic-productivity-tools">Basic Productivity Tools</h2> <p>This is a running list of basic productivity tools that one can download online. Some might need additional set up, more on this later.</p> <ul> <li>browsers: brave</li> <li>terminal: iterm2</li> <li>chat: discord</li> <li>ide: vscode</li> <li>notepad: obsidian</li> <li>copyclip to access copy history</li> </ul> <h2 id="terminal">Terminal</h2> <ul> <li>xcode for mac</li> <li>install <a href="https://brew.sh/">Homebrew</a></li> <li>install oh-my-zsh <a href="https://github.com/ohmyzsh/ohmyzsh">instructions</a></li> <li>Edit settings to pick <code class="language-plaintext highlighter-rouge">solarized dark</code> theme and <code class="language-plaintext highlighter-rouge">Menlo</code> size 14 fonts</li> <li>Setting up ssh key <a href="https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent">instructions</a></li> <li>Add ssh key to github <a href="https://docs.github.com/en/authentication/connecting-to-github-with-ssh/adding-a-new-ssh-key-to-your-github-account">instructions</a></li> <li>install anaconda</li> <li>install <a href="https://realpython.com/intro-to-pyenv">pyenv</a></li> </ul> <h2 id="vscode">VSCode</h2> <ul> <li>Choose theme</li> <li>highlighting</li> <li>Apply on save editing</li> <li>copilot?</li> </ul> <p>## Obsidian</p> <ul> <li>set up obsidian to work off a cloud drive <a href="https://www.makeuseof.com/sync-obsidian-vault-across-devices/">instructions</a></li> </ul>]]></content><author><name></name></author><summary type="html"><![CDATA[This is a post for mostly personal use (more than my personal average :) ). Having to set up a new laptop is one of those events that fall in the optimal postponing zone. Happens regularly to annoy you but infrequently to justify solving it systematically. So you only remember it when it happens and you put off solving it for another few years because “why spend extra time on it now?”.]]></summary></entry><entry><title type="html">Recreating the US birthday analysis with Prophet</title><link href="https://bayesways.github.io/blog/2023/recreating-the-US-birthday-analysis/" rel="alternate" type="text/html" title="Recreating the US birthday analysis with Prophet"/><published>2023-03-14T00:00:00+00:00</published><updated>2023-03-14T00:00:00+00:00</updated><id>https://bayesways.github.io/blog/2023/recreating-the-US-birthday-analysis</id><content type="html" xml:base="https://bayesways.github.io/blog/2023/recreating-the-US-birthday-analysis/"><![CDATA[<h2 id="background">Background</h2> <p>In this post I will try to model the number of births in the US, using seasonal effects, day of week effects and special holiday effects. The original analysis used Gaussian Processes, it was included in BDA3 (on the cover actually). In the first version of the book the model was too big to be fit with Stan, so it was fit with a different package called <code class="language-plaintext highlighter-rouge">GPStuff</code>. <a href="https://research.cs.aalto.fi/pml/software/gpstuff/demo_births.shtml">Here</a> is the code that created the materials of the book.</p> <p>Since then Stan has improved further and it looks like it is now possible to fit the original model Stan, as explained in this recent <a href="https://avehtari.github.io/casestudies/Birthdays/birthdays.html">post</a> by Aki Vehtari.</p> <p>As described in the book, and a series of posts such as <a href="https://statmodeling.stat.columbia.edu/2016/05/18/birthday-analysis-friday-the-13th-update/">this</a> on Andrew Gelman’s blog, the question was whether there are excess births on Valentine’s day and fewer births on Halloween. This question provided an excuse to examine the effect of any holiday in the US, and more generally any day of the year. It also served as an excuse to demonstrate the use of Gaussian Processes as a time series decomposition technique.</p> <p>Here is the headline chart from that analys (recreated here from the gpstuff <a href="https://research.cs.aalto.fi/pml/software/gpstuff/demo_births.shtml">page</a>):</p> <div class="col-sm mt-3 mt-md-0"><figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2023-03-14-recreating-the-US-birthday-analysis/birthday_files/births_pic2-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2023-03-14-recreating-the-US-birthday-analysis/birthday_files/births_pic2-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2023-03-14-recreating-the-US-birthday-analysis/birthday_files/births_pic2-1400.webp"/> <img src="/assets/img/2023-03-14-recreating-the-US-birthday-analysis/birthday_files/births_pic2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <h2 id="plan-for-this-post">Plan for this post</h2> <p>Here I try to the same analysis but using a simpler additive model based on Fourier Transforms, instead of Gaussian Processes. I am also using it as an excuse to learn how <a href="https://facebook.github.io/prophet/">Prophet</a> works, a package for time series forecasting implemented by a team at facebook.</p> <p>Tha package is pretty simple to use and fast to fit. I was able to get most of the paterns right with little experimentation, though not completely right. The ease of use and the ability to add custom components makes Prophet a great tool. The most obvious drawback is that it’s made to accommodate daily data and there is no easy way to generalize to other frequencies.</p> <h2 id="setup">Setup</h2> <p>Load packages</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">prophet</span> <span class="kn">import</span> <span class="n">Prophet</span>
<span class="kn">import</span> <span class="n">altair</span> <span class="k">as</span> <span class="n">alt</span>
<span class="kn">import</span> <span class="n">holidays</span>
<span class="kn">from</span> <span class="n">prophet.plot</span> <span class="kn">import</span> <span class="n">add_changepoints_to_plot</span>
<span class="n">alt</span><span class="p">.</span><span class="n">data_transformers</span><span class="p">.</span><span class="nf">enable</span><span class="p">(</span><span class="sh">'</span><span class="s">default</span><span class="sh">'</span><span class="p">,</span> <span class="n">max_rows</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
</code></pre></div></div> <p>Get data</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">https://raw.githubusercontent.com/avehtari/casestudies/master/Birthdays/data/births_usa_1969.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">ds</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">year</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span><span class="o">+</span><span class="sh">'</span><span class="s">-</span><span class="sh">'</span><span class="o">+</span><span class="n">df</span><span class="p">.</span><span class="n">month</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span><span class="o">+</span><span class="sh">'</span><span class="s">-</span><span class="sh">'</span><span class="o">+</span><span class="n">df</span><span class="p">.</span><span class="n">day</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">))</span>
<span class="n">df</span><span class="p">.</span><span class="nf">rename</span><span class="p">({</span><span class="sh">'</span><span class="s">births</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">},</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="sh">'</span><span class="s">ds</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">]]</span>
<span class="n">df</span><span class="p">.</span><span class="nf">head</span><span class="p">()</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>ds</th> <th>y</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>1969-01-01</td> <td>8486</td> </tr> <tr> <th>1</th> <td>1969-01-02</td> <td>9002</td> </tr> <tr> <th>2</th> <td>1969-01-03</td> <td>9542</td> </tr> <tr> <th>3</th> <td>1969-01-04</td> <td>8960</td> </tr> <tr> <th>4</th> <td>1969-01-05</td> <td>8390</td> </tr> </tbody> </table> </div> <h2 id="model-definition">Model Definition</h2> <p>Define the standard model and add a custom effect that I call “each_day”. It has <code class="language-plaintext highlighter-rouge">period</code> 365.25 because I want to model each day of the year. It also has a high <code class="language-plaintext highlighter-rouge">fourier_order</code> to make it very flexible. I experimented with lower values and found that I need a fairly high value to pick up the signals I am looking for. More experimentation is needed to pick this value though.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">m</span> <span class="o">=</span> <span class="nc">Prophet</span><span class="p">(</span><span class="n">changepoint_prior_scale</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span> <span class="n">yearly_seasonality</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="c1">## add effect for day of the year effect for more long term patters
</span><span class="n">m</span><span class="p">.</span><span class="nf">add_seasonality</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">each_day_long_term</span><span class="sh">'</span><span class="p">,</span> <span class="n">period</span><span class="o">=</span><span class="mf">365.25</span><span class="p">,</span> <span class="n">fourier_order</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="c1">## add effect for day of the year: 
</span><span class="n">m</span><span class="p">.</span><span class="nf">add_seasonality</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">each_day</span><span class="sh">'</span><span class="p">,</span> <span class="n">period</span><span class="o">=</span><span class="mf">365.25</span><span class="p">,</span> <span class="n">fourier_order</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">m</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>17:03:30 - cmdstanpy - INFO - Chain [1] start processing
17:03:59 - cmdstanpy - INFO - Chain [1] done processing





&lt;prophet.forecaster.Prophet at 0x7fe099e03910&gt;
</code></pre></div></div> <p>Fit the model to data</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">future</span> <span class="o">=</span> <span class="n">m</span><span class="p">.</span><span class="nf">make_future_dataframe</span><span class="p">(</span><span class="n">periods</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">future</span><span class="p">.</span><span class="nf">tail</span><span class="p">()</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>ds</th> </tr> </thead> <tbody> <tr> <th>7301</th> <td>1988-12-28</td> </tr> <tr> <th>7302</th> <td>1988-12-29</td> </tr> <tr> <th>7303</th> <td>1988-12-30</td> </tr> <tr> <th>7304</th> <td>1988-12-31</td> </tr> <tr> <th>7305</th> <td>1989-01-01</td> </tr> </tbody> </table> </div> <p>Generate estimates and forecasts</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">forecast</span> <span class="o">=</span> <span class="n">m</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">future</span><span class="p">)</span>
<span class="n">forecast</span><span class="p">[[</span><span class="sh">'</span><span class="s">ds</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">yhat</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">yhat_lower</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">yhat_upper</span><span class="sh">'</span><span class="p">]].</span><span class="nf">tail</span><span class="p">()</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>ds</th> <th>yhat</th> <th>yhat_lower</th> <th>yhat_upper</th> </tr> </thead> <tbody> <tr> <th>7301</th> <td>1988-12-28</td> <td>11680.646441</td> <td>11239.300965</td> <td>12094.109632</td> </tr> <tr> <th>7302</th> <td>1988-12-29</td> <td>11724.885805</td> <td>11294.168795</td> <td>12215.288371</td> </tr> <tr> <th>7303</th> <td>1988-12-30</td> <td>11502.343208</td> <td>11071.599362</td> <td>11957.702909</td> </tr> <tr> <th>7304</th> <td>1988-12-31</td> <td>9078.021852</td> <td>8622.992957</td> <td>9533.391236</td> </tr> <tr> <th>7305</th> <td>1989-01-01</td> <td>7960.215673</td> <td>7521.253713</td> <td>8409.581555</td> </tr> </tbody> </table> </div> <p>Create the basic plot of the underlying trend. I chose to visualize the change points for more clarity. The exacat number of points is a choice that requires callibration but I think it does not affect my problem too much so I move on.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">fig1</span> <span class="o">=</span> <span class="n">m</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">forecast</span><span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="nf">add_changepoints_to_plot</span><span class="p">(</span><span class="n">fig1</span><span class="p">.</span><span class="nf">gca</span><span class="p">(),</span> <span class="n">m</span><span class="p">,</span> <span class="n">forecast</span><span class="p">)</span>
</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"><figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2023-03-14-recreating-the-US-birthday-analysis/birthday_files/birthday_7_0-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2023-03-14-recreating-the-US-birthday-analysis/birthday_files/birthday_7_0-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2023-03-14-recreating-the-US-birthday-analysis/birthday_files/birthday_7_0-1400.webp"/> <img src="/assets/img/2023-03-14-recreating-the-US-birthday-analysis/birthday_files/birthday_7_0.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>Create the plot of all the different components. This is an automatic output from <code class="language-plaintext highlighter-rouge">Prophet</code> and it is fairly close to the headline chart of the original analysis. But we are missing the key chart of the day of year (see below).</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig2</span> <span class="o">=</span> <span class="n">m</span><span class="p">.</span><span class="nf">plot_components</span><span class="p">(</span><span class="n">forecast</span><span class="p">)</span>

</code></pre></div></div> <div class="col-sm mt-3 mt-md-0"><figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/2023-03-14-recreating-the-US-birthday-analysis/birthday_files/birthday_8_0-480.webp"/> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/2023-03-14-recreating-the-US-birthday-analysis/birthday_files/birthday_8_0-800.webp"/> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/2023-03-14-recreating-the-US-birthday-analysis/birthday_files/birthday_8_0-1400.webp"/> <img src="/assets/img/2023-03-14-recreating-the-US-birthday-analysis/birthday_files/birthday_8_0.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>And finally here we create the day of the year plot we were aiming for.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">day_of_year_effect</span> <span class="o">=</span> <span class="n">forecast</span><span class="p">[[</span><span class="sh">'</span><span class="s">ds</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">each_day</span><span class="sh">'</span><span class="p">]].</span><span class="nf">copy</span><span class="p">()</span>
<span class="n">day_of_year_effect</span><span class="p">[</span><span class="sh">'</span><span class="s">indicative_day</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">1999</span><span class="sh">'</span> <span class="o">+</span><span class="sh">'</span><span class="s">-</span><span class="sh">'</span> <span class="o">+</span> <span class="n">day_of_year_effect</span><span class="p">[</span><span class="sh">'</span><span class="s">ds</span><span class="sh">'</span><span class="p">].</span><span class="n">dt</span><span class="p">.</span><span class="n">month</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span> <span class="o">+</span><span class="sh">'</span><span class="s">-</span><span class="sh">'</span> <span class="o">+</span> <span class="n">day_of_year_effect</span><span class="p">[</span><span class="sh">'</span><span class="s">ds</span><span class="sh">'</span><span class="p">].</span><span class="n">dt</span><span class="p">.</span><span class="n">day</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="n">day_of_year_effect</span> <span class="o">=</span> <span class="n">day_of_year_effect</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="sh">'</span><span class="s">indicative_day</span><span class="sh">'</span><span class="p">)[[</span><span class="sh">'</span><span class="s">each_day</span><span class="sh">'</span><span class="p">]].</span><span class="nf">mean</span><span class="p">().</span><span class="nf">reset_index</span><span class="p">()</span>
<span class="n">day_of_year_effect</span>
</code></pre></div></div> <div> <style scoped="">.dataframe tbody tr th:only-of-type{vertical-align:middle}.dataframe tbody tr th{vertical-align:top}.dataframe thead th{text-align:right}</style> <table border="1" class="dataframe"> <thead> <tr style="text-align: right;"> <th></th> <th>indicative_day</th> <th>each_day</th> </tr> </thead> <tbody> <tr> <th>0</th> <td>1999-1-1</td> <td>-1.301688</td> </tr> <tr> <th>1</th> <td>1999-1-10</td> <td>-0.163488</td> </tr> <tr> <th>2</th> <td>1999-1-11</td> <td>-0.017994</td> </tr> <tr> <th>3</th> <td>1999-1-12</td> <td>-0.053865</td> </tr> <tr> <th>4</th> <td>1999-1-13</td> <td>-0.081956</td> </tr> <tr> <th>...</th> <td>...</td> <td>...</td> </tr> <tr> <th>361</th> <td>1999-9-5</td> <td>0.077351</td> </tr> <tr> <th>362</th> <td>1999-9-6</td> <td>0.131178</td> </tr> <tr> <th>363</th> <td>1999-9-7</td> <td>0.119668</td> </tr> <tr> <th>364</th> <td>1999-9-8</td> <td>0.314853</td> </tr> <tr> <th>365</th> <td>1999-9-9</td> <td>0.463697</td> </tr> </tbody> </table> <p>366 rows × 2 columns</p> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig3</span> <span class="o">=</span> <span class="n">alt</span><span class="p">.</span><span class="nc">Chart</span><span class="p">(</span><span class="n">day_of_year_effect</span><span class="p">).</span><span class="nf">mark_line</span><span class="p">().</span><span class="nf">encode</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="sh">'</span><span class="s">indicative_day:T</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="sh">'</span><span class="s">each_day</span><span class="sh">'</span>
<span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">holiday_data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">.</span><span class="nf">from_dict</span><span class="p">(</span><span class="n">holidays</span><span class="p">.</span><span class="nc">US</span><span class="p">(</span><span class="n">years</span><span class="o">=</span><span class="n">forecast</span><span class="p">[</span><span class="sh">'</span><span class="s">ds</span><span class="sh">'</span><span class="p">].</span><span class="n">dt</span><span class="p">.</span><span class="n">year</span><span class="p">.</span><span class="n">values</span><span class="p">).</span><span class="nf">items</span><span class="p">())</span>
<span class="n">holiday_data</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">ds</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">holiday</span><span class="sh">'</span><span class="p">]</span>
<span class="n">holiday_data</span><span class="p">[</span><span class="sh">'</span><span class="s">ds</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">holiday_data</span><span class="p">[</span><span class="sh">'</span><span class="s">ds</span><span class="sh">'</span><span class="p">])</span>

<span class="n">ignore_observed_dates</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">ignore_index</span> <span class="o">=</span> <span class="n">holiday_data</span><span class="p">[</span><span class="sh">'</span><span class="s">holiday</span><span class="sh">'</span><span class="p">][</span><span class="n">holiday_data</span><span class="p">[</span><span class="sh">'</span><span class="s">holiday</span><span class="sh">'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="nf">contains</span><span class="p">(</span><span class="sh">'</span><span class="s">Observed</span><span class="sh">'</span><span class="p">)].</span><span class="n">index</span>
<span class="n">holiday_data_without_observed</span> <span class="o">=</span> <span class="n">holiday_data</span><span class="p">[</span><span class="o">~</span><span class="n">holiday_data</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="nf">isin</span><span class="p">(</span><span class="n">ignore_index</span><span class="p">)]</span>
<span class="k">if</span> <span class="n">ignore_observed_dates</span><span class="p">:</span>
    <span class="n">holiday_data</span> <span class="o">=</span> <span class="n">holiday_data_without_observed</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">holiday_effect</span> <span class="o">=</span> <span class="n">forecast</span><span class="p">[[</span><span class="sh">'</span><span class="s">ds</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">each_day</span><span class="sh">'</span><span class="p">]].</span><span class="nf">merge</span><span class="p">(</span><span class="n">holiday_data</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="sh">'</span><span class="s">ds</span><span class="sh">'</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="sh">'</span><span class="s">outer</span><span class="sh">'</span><span class="p">).</span><span class="nf">groupby</span><span class="p">(</span><span class="sh">'</span><span class="s">holiday</span><span class="sh">'</span><span class="p">).</span><span class="nf">agg</span><span class="p">({</span><span class="sh">'</span><span class="s">ds</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">first</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">each_day</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">mean</span><span class="sh">'</span><span class="p">}).</span><span class="nf">reset_index</span><span class="p">()</span>
<span class="n">holiday_effect</span><span class="p">.</span><span class="nf">rename</span><span class="p">({</span><span class="sh">'</span><span class="s">each_day</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">effect size</span><span class="sh">'</span><span class="p">},</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">holiday_effect</span><span class="p">[</span><span class="sh">'</span><span class="s">indicative_day</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">1999</span><span class="sh">'</span> <span class="o">+</span><span class="sh">'</span><span class="s">-</span><span class="sh">'</span> <span class="o">+</span> <span class="n">holiday_effect</span><span class="p">[</span><span class="sh">'</span><span class="s">ds</span><span class="sh">'</span><span class="p">].</span><span class="n">dt</span><span class="p">.</span><span class="n">month</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span> <span class="o">+</span><span class="sh">'</span><span class="s">-</span><span class="sh">'</span> <span class="o">+</span> <span class="n">holiday_effect</span><span class="p">[</span><span class="sh">'</span><span class="s">ds</span><span class="sh">'</span><span class="p">].</span><span class="n">dt</span><span class="p">.</span><span class="n">day</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>

</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig4</span> <span class="o">=</span> <span class="n">alt</span><span class="p">.</span><span class="nc">Chart</span><span class="p">(</span><span class="n">holiday_effect</span><span class="p">).</span><span class="nf">mark_text</span><span class="p">().</span><span class="nf">encode</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="sh">'</span><span class="s">indicative_day:T</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="sh">'</span><span class="s">effect size</span><span class="sh">'</span><span class="p">,</span>
    <span class="n">text</span><span class="o">=</span><span class="sh">'</span><span class="s">holiday</span><span class="sh">'</span>
<span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">fig3</span> <span class="o">+</span> <span class="n">fig4</span> <span class="p">).</span><span class="nf">properties</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">250</span><span class="p">)</span>
</code></pre></div></div> <div id="altair-viz-5f10a9cb885a4675a84cfcada1776064"></div> <script type="text/javascript">var VEGA_DEBUG=void 0===VEGA_DEBUG?{}:VEGA_DEBUG;!function(a,i){function d(a,i){var d=`${a.replace("-","")}_version`;return VEGA_DEBUG[d]==i?Promise.resolve(_[a]):new Promise(function(e,c){var y=document.createElement("script");document.getElementsByTagName("head")[0].appendChild(y),y.async=!0,y.onload=(()=>(VEGA_DEBUG[d]=i,e(_[a]))),y.onerror=(()=>c(`Error loading script: ${_[a]}`)),y.src=_[a]})}function e(a){throw y.innerHTML=`<div class="error" style="color:red;">${a}</div>`,a}function c(d){d(y,a,i)["catch"](a=>e(`Javascript Error: ${a.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`))}let y=document.currentScript.previousElementSibling;"altair-viz-5f10a9cb885a4675a84cfcada1776064"!==y.id&&(y=document.getElementById("altair-viz-5f10a9cb885a4675a84cfcada1776064"));const _={vega:"https://cdn.jsdelivr.net/npm//vega@5?noext","vega-lib":"https://cdn.jsdelivr.net/npm//vega-lib?noext","vega-lite":"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext","vega-embed":"https://cdn.jsdelivr.net/npm//vega-embed@6?noext"};"function"==typeof define&&define.amd?(requirejs.config({paths:_}),require(["vega-embed"],c,a=>e(`Error loading script: ${a.message}`))):d("vega","5").then(()=>d("vega-lite","4.17.0")).then(()=>d("vega-embed","6"))["catch"](e).then(()=>c(vegaEmbed))}({config:{view:{continuousWidth:400,continuousHeight:300}},layer:[{data:{name:"data-d373b8b478dabceb4050e1a3a9f78682"},mark:"line",encoding:{x:{field:"indicative_day",type:"temporal"},y:{field:"each_day",type:"quantitative"}}},{data:{name:"data-25713872bd7ea71ecc827a8ebbaa6350"},mark:"text",encoding:{text:{field:"holiday",type:"nominal"},x:{field:"indicative_day",type:"temporal"},y:{field:"effect size",type:"quantitative"}}}],height:250,width:600,$schema:"https://vega.github.io/schema/vega-lite/v4.17.0.json",datasets:{"data-d373b8b478dabceb4050e1a3a9f78682":[{indicative_day:"1999-1-1",each_day:-935.7558852651148},{indicative_day:"1999-1-10",each_day:-167.22771517510358},{indicative_day:"1999-1-11",each_day:41.69885106293092},{indicative_day:"1999-1-12",each_day:36.745962343884486},{indicative_day:"1999-1-13",each_day:-43.683339049571586},{indicative_day:"1999-1-14",each_day:-7.256157432204264},{indicative_day:"1999-1-15",each_day:-.49051032887007506},{indicative_day:"1999-1-16",each_day:-97.8576898381739},{indicative_day:"1999-1-17",each_day:-95.74960389957083},{indicative_day:"1999-1-18",each_day:31.86298345941254},{indicative_day:"1999-1-19",each_day:57.695956293300696},{indicative_day:"1999-1-2",each_day:-1000.2816025419343},{indicative_day:"1999-1-20",each_day:-37.52892311828231},{indicative_day:"1999-1-21",each_day:-72.49957526527263},{indicative_day:"1999-1-22",each_day:-58.84118026132844},{indicative_day:"1999-1-23",each_day:-103.9915377566982},{indicative_day:"1999-1-24",each_day:-121.90630998182658},{indicative_day:"1999-1-25",each_day:-39.62069375884529},{indicative_day:"1999-1-26",each_day:-1.0023441706092113},{indicative_day:"1999-1-27",each_day:-77.13314248376221},{indicative_day:"1999-1-28",each_day:-130.41135957893803},{indicative_day:"1999-1-29",each_day:-125.7779418372298},{indicative_day:"1999-1-3",each_day:-381.8294907262302},{indicative_day:"1999-1-30",each_day:-169.9086459625696},{indicative_day:"1999-1-31",each_day:-204.43159629837675},{indicative_day:"1999-1-4",each_day:-9.986476979049794},{indicative_day:"1999-1-5",each_day:-114.06712279424126},{indicative_day:"1999-1-6",each_day:-172.715689343198},{indicative_day:"1999-1-7",each_day:-83.18535497250606},{indicative_day:"1999-1-8",each_day:-158.7035984458442},{indicative_day:"1999-1-9",each_day:-290.5893367021596},{indicative_day:"1999-10-1",each_day:216.523669372401},{indicative_day:"1999-10-10",each_day:117.3328085314949},{indicative_day:"1999-10-11",each_day:88.35624709103766},{indicative_day:"1999-10-12",each_day:16.04608785597697},{indicative_day:"1999-10-13",each_day:6.526906500616962},{indicative_day:"1999-10-14",each_day:53.39476114674765},{indicative_day:"1999-10-15",each_day:63.07218199220646},{indicative_day:"1999-10-16",each_day:20.402022251105972},{indicative_day:"1999-10-17",each_day:-18.135344681859586},{indicative_day:"1999-10-18",each_day:-32.60097228834169},{indicative_day:"1999-10-19",each_day:-28.336275378597982},{indicative_day:"1999-10-2",each_day:158.6405460165194},{indicative_day:"1999-10-20",each_day:-3.4040688263262053},{indicative_day:"1999-10-21",each_day:5.954273215563765},{indicative_day:"1999-10-22",each_day:-41.53121983548594},{indicative_day:"1999-10-23",each_day:-95.10595378887363},{indicative_day:"1999-10-24",each_day:-78.10830554809392},{indicative_day:"1999-10-25",each_day:-24.04854188832745},{indicative_day:"1999-10-26",each_day:-10.512970289865832},{indicative_day:"1999-10-27",each_day:-28.02268704961359},{indicative_day:"1999-10-28",each_day:-45.60421816560179},{indicative_day:"1999-10-29",each_day:-96.86609294818065},{indicative_day:"1999-10-3",each_day:126.23663953598286},{indicative_day:"1999-10-30",each_day:-181.26760225153797},{indicative_day:"1999-10-31",each_day:-211.91415618802344},{indicative_day:"1999-10-4",each_day:120.98991453138781},{indicative_day:"1999-10-5",each_day:125.36635526706861},{indicative_day:"1999-10-6",each_day:113.44684473384264},{indicative_day:"1999-10-7",each_day:69.73656736317585},{indicative_day:"1999-10-8",each_day:37.752793332370814},{indicative_day:"1999-10-9",each_day:70.23275949818023},{indicative_day:"1999-11-1",each_day:-155.01260345045887},{indicative_day:"1999-11-10",each_day:17.29787810908705},{indicative_day:"1999-11-11",each_day:-6.843439626582186},{indicative_day:"1999-11-12",each_day:-23.749232274863186},{indicative_day:"1999-11-13",each_day:-42.55863835824413},{indicative_day:"1999-11-14",each_day:-25.552784347272162},{indicative_day:"1999-11-15",each_day:43.27981038445536},{indicative_day:"1999-11-16",each_day:91.17693161805903},{indicative_day:"1999-11-17",each_day:87.55404360335119},{indicative_day:"1999-11-18",each_day:108.91152450919148},{indicative_day:"1999-11-19",each_day:166.72194872899394},{indicative_day:"1999-11-2",each_day:-84.3158188996765},{indicative_day:"1999-11-20",each_day:153.2765087592175},{indicative_day:"1999-11-21",each_day:38.41111842980369},{indicative_day:"1999-11-22",each_day:-83.55608147912676},{indicative_day:"1999-11-23",each_day:-173.67359620616935},{indicative_day:"1999-11-24",each_day:-268.4098140222778},{indicative_day:"1999-11-25",each_day:-349.8469678934718},{indicative_day:"1999-11-26",each_day:-381.77104866713387},{indicative_day:"1999-11-27",each_day:-378.8818489453457},{indicative_day:"1999-11-28",each_day:-308.47405438490966},{indicative_day:"1999-11-29",each_day:-112.2950796322184},{indicative_day:"1999-11-3",each_day:-51.15438119287971},{indicative_day:"1999-11-30",each_day:93.39884758758122},{indicative_day:"1999-11-4",each_day:-40.16541555801091},{indicative_day:"1999-11-5",each_day:-48.758767581053874},{indicative_day:"1999-11-6",each_day:-73.51578810629715},{indicative_day:"1999-11-7",each_day:-64.387379747513},{indicative_day:"1999-11-8",each_day:-7.334981752257742},{indicative_day:"1999-11-9",each_day:31.053482371791763},{indicative_day:"1999-12-1",each_day:112.47590964582164},{indicative_day:"1999-12-10",each_day:-81.19607809580974},{indicative_day:"1999-12-11",each_day:-26.768199999878128},{indicative_day:"1999-12-12",each_day:-47.33761731683906},{indicative_day:"1999-12-13",each_day:-88.62414336426346},{indicative_day:"1999-12-14",each_day:43.72397490997906},{indicative_day:"1999-12-15",each_day:249.87720076969308},{indicative_day:"1999-12-16",each_day:291.6369465109428},{indicative_day:"1999-12-17",each_day:266.4623934185708},{indicative_day:"1999-12-18",each_day:365.09652852151504},{indicative_day:"1999-12-19",each_day:428.66055376524065},{indicative_day:"1999-12-2",each_day:-7.037447635432182},{indicative_day:"1999-12-20",each_day:291.3668888960177},{indicative_day:"1999-12-21",each_day:113.25064898795783},{indicative_day:"1999-12-22",each_day:-110.39582213350778},{indicative_day:"1999-12-23",each_day:-683.6444298294327},{indicative_day:"1999-12-24",each_day:-1395.7989591043115},{indicative_day:"1999-12-25",each_day:-1454.3236428974549},{indicative_day:"1999-12-26",each_day:-677.4919782626296},{indicative_day:"1999-12-27",each_day:197.61222330845803},{indicative_day:"1999-12-28",each_day:678.1143054280035},{indicative_day:"1999-12-29",each_day:898.6101511823645},{indicative_day:"1999-12-3",each_day:-61.208055539195016},{indicative_day:"1999-12-30",each_day:755.0459979605791},{indicative_day:"1999-12-31",each_day:-32.53015358177504},{indicative_day:"1999-12-4",each_day:-49.30533040295741},{indicative_day:"1999-12-5",each_day:-92.28396855042838},{indicative_day:"1999-12-6",each_day:-131.66953678243283},{indicative_day:"1999-12-7",each_day:-74.65624317897584},{indicative_day:"1999-12-8",each_day:-29.080753219759686},{indicative_day:"1999-12-9",each_day:-72.43640779879829},{indicative_day:"1999-2-1",each_day:-96.70319360381444},{indicative_day:"1999-2-10",each_day:54.998997759052806},{indicative_day:"1999-2-11",each_day:-10.328474744496077},{indicative_day:"1999-2-12",each_day:-54.12633580021348},{indicative_day:"1999-2-13",each_day:15.855948510659076},{indicative_day:"1999-2-14",each_day:84.60330693986553},{indicative_day:"1999-2-15",each_day:61.20577131902977},{indicative_day:"1999-2-16",each_day:3.630501226949434},{indicative_day:"1999-2-17",each_day:-33.82508502984295},{indicative_day:"1999-2-18",each_day:-66.49273238561993},{indicative_day:"1999-2-19",each_day:-90.518106397009},{indicative_day:"1999-2-2",each_day:29.39541329099755},{indicative_day:"1999-2-20",each_day:-80.99939394513878},{indicative_day:"1999-2-21",each_day:-50.24193831339997},{indicative_day:"1999-2-22",each_day:-20.242283842904662},{indicative_day:"1999-2-23",each_day:7.339463225409266},{indicative_day:"1999-2-24",each_day:18.310184903264485},{indicative_day:"1999-2-25",each_day:-9.142565315530673},{indicative_day:"1999-2-26",each_day:-64.23083522904346},{indicative_day:"1999-2-27",each_day:-116.58108270058581},{indicative_day:"1999-2-28",each_day:-137.11630148022894},{indicative_day:"1999-2-29",each_day:-121.18669783158775},{indicative_day:"1999-2-3",each_day:-17.291363529970308},{indicative_day:"1999-2-4",each_day:-130.60107693820788},{indicative_day:"1999-2-5",each_day:-123.72771384408338},{indicative_day:"1999-2-6",each_day:-73.519192199311},{indicative_day:"1999-2-7",each_day:-101.29714102146902},{indicative_day:"1999-2-8",each_day:-104.33597986424786},{indicative_day:"1999-2-9",each_day:-4.060833892686466},{indicative_day:"1999-3-1",each_day:-69.15125299755417},{indicative_day:"1999-3-10",each_day:-37.215975446165764},{indicative_day:"1999-3-11",each_day:-54.371884159651664},{indicative_day:"1999-3-12",each_day:-92.98543836681799},{indicative_day:"1999-3-13",each_day:-119.49668903073457},{indicative_day:"1999-3-14",each_day:-119.70211036160303},{indicative_day:"1999-3-15",each_day:-84.62265059434438},{indicative_day:"1999-3-16",each_day:-14.020901958111242},{indicative_day:"1999-3-17",each_day:36.21929981173235},{indicative_day:"1999-3-18",each_day:6.4601834017454935},{indicative_day:"1999-3-19",each_day:-58.49529437396294},{indicative_day:"1999-3-2",each_day:37.232252816640006},{indicative_day:"1999-3-20",each_day:-69.60026546013924},{indicative_day:"1999-3-21",each_day:-41.76594423561106},{indicative_day:"1999-3-22",each_day:-49.263380346095225},{indicative_day:"1999-3-23",each_day:-78.70017871350221},{indicative_day:"1999-3-24",each_day:-71.69293598296856},{indicative_day:"1999-3-25",each_day:-54.65734915330595},{indicative_day:"1999-3-26",each_day:-80.53787324743979},{indicative_day:"1999-3-27",each_day:-108.27478952665528},{indicative_day:"1999-3-28",each_day:-78.12438264345569},{indicative_day:"1999-3-29",each_day:-39.05435452247046},{indicative_day:"1999-3-3",each_day:84.83732231677743},{indicative_day:"1999-3-30",each_day:-73.49272245381822},{indicative_day:"1999-3-31",each_day:-151.9146234717227},{indicative_day:"1999-3-4",each_day:26.331333753166813},{indicative_day:"1999-3-5",each_day:-58.99551884467176},{indicative_day:"1999-3-6",each_day:-88.06487286005405},{indicative_day:"1999-3-7",each_day:-76.45974554238744},{indicative_day:"1999-3-8",each_day:-64.23726635638651},{indicative_day:"1999-3-9",each_day:-49.34280571977802},{indicative_day:"1999-4-1",each_day:-175.33480798397062},{indicative_day:"1999-4-10",each_day:-178.4296442933059},{indicative_day:"1999-4-11",each_day:-167.59985177573594},{indicative_day:"1999-4-12",each_day:-163.8165103041972},{indicative_day:"1999-4-13",each_day:-155.19873566806618},{indicative_day:"1999-4-14",each_day:-108.50866871153593},{indicative_day:"1999-4-15",each_day:-68.47832702857805},{indicative_day:"1999-4-16",each_day:-90.34857390581166},{indicative_day:"1999-4-17",each_day:-127.66183971989372},{indicative_day:"1999-4-18",each_day:-116.43706420990031},{indicative_day:"1999-4-19",each_day:-91.99321865379859},{indicative_day:"1999-4-2",each_day:-127.4733752287174},{indicative_day:"1999-4-20",each_day:-101.74884814952105},{indicative_day:"1999-4-21",each_day:-109.30083403030945},{indicative_day:"1999-4-22",each_day:-92.92523084721118},{indicative_day:"1999-4-23",each_day:-106.50200617303237},{indicative_day:"1999-4-24",each_day:-153.30797693567365},{indicative_day:"1999-4-25",each_day:-153.7517449137093},{indicative_day:"1999-4-26",each_day:-105.8640056373888},{indicative_day:"1999-4-27",each_day:-107.84898652318574},{indicative_day:"1999-4-28",each_day:-174.40005892380591},{indicative_day:"1999-4-29",each_day:-204.31914353289653},{indicative_day:"1999-4-3",each_day:-89.72338131090646},{indicative_day:"1999-4-30",each_day:-159.48482036653382},{indicative_day:"1999-4-4",each_day:-111.18013921526024},{indicative_day:"1999-4-5",each_day:-141.0979224484337},{indicative_day:"1999-4-6",each_day:-120.2791340227246},{indicative_day:"1999-4-7",each_day:-82.24903163034746},{indicative_day:"1999-4-8",each_day:-97.4831186724265},{indicative_day:"1999-4-9",each_day:-152.93444477760468},{indicative_day:"1999-5-1",each_day:-115.42192589493455},{indicative_day:"1999-5-10",each_day:-93.29595046215533},{indicative_day:"1999-5-11",each_day:-44.49701451458332},{indicative_day:"1999-5-12",each_day:-94.70707465145308},{indicative_day:"1999-5-13",each_day:-157.98532469809376},{indicative_day:"1999-5-14",each_day:-134.6214900738162},{indicative_day:"1999-5-15",each_day:-78.59178904059331},{indicative_day:"1999-5-16",each_day:-76.31298242134257},{indicative_day:"1999-5-17",each_day:-89.08797628624919},{indicative_day:"1999-5-18",each_day:-49.20635049842059},{indicative_day:"1999-5-19",each_day:6.521309498788183},{indicative_day:"1999-5-2",each_day:-122.97007611003046},{indicative_day:"1999-5-20",each_day:12.208733662913328},{indicative_day:"1999-5-21",each_day:-14.897305115803652},{indicative_day:"1999-5-22",each_day:-20.77917034736404},{indicative_day:"1999-5-23",each_day:-7.407707381731993},{indicative_day:"1999-5-24",each_day:-25.251376689736666},{indicative_day:"1999-5-25",each_day:-93.51942032383405},{indicative_day:"1999-5-26",each_day:-152.39836229490498},{indicative_day:"1999-5-27",each_day:-134.88837995529667},{indicative_day:"1999-5-28",each_day:-93.91722705033425},{indicative_day:"1999-5-29",each_day:-146.64214828328062},{indicative_day:"1999-5-3",each_day:-150.3300479098979},{indicative_day:"1999-5-30",each_day:-247.97142121750932},{indicative_day:"1999-5-31",each_day:-206.46716706137445},{indicative_day:"1999-5-4",each_day:-154.85167647342735},{indicative_day:"1999-5-5",each_day:-127.07423587583492},{indicative_day:"1999-5-6",each_day:-93.1178599317723},{indicative_day:"1999-5-7",each_day:-102.2295343652224},{indicative_day:"1999-5-8",each_day:-153.56332091445685},{indicative_day:"1999-5-9",each_day:-162.93973738340372},{indicative_day:"1999-6-1",each_day:-15.122679175448102},{indicative_day:"1999-6-10",each_day:14.827199141635381},{indicative_day:"1999-6-11",each_day:-40.70404302987099},{indicative_day:"1999-6-12",each_day:-128.75289683261371},{indicative_day:"1999-6-13",each_day:-152.9883248812908},{indicative_day:"1999-6-14",each_day:-112.89540253865388},{indicative_day:"1999-6-15",each_day:-26.445831938431905},{indicative_day:"1999-6-16",each_day:56.09292160217965},{indicative_day:"1999-6-17",each_day:42.586883836837465},{indicative_day:"1999-6-18",each_day:-43.08676975537468},{indicative_day:"1999-6-19",each_day:-57.04261745596623},{indicative_day:"1999-6-2",each_day:81.89554557857899},{indicative_day:"1999-6-20",each_day:7.378474726932813},{indicative_day:"1999-6-21",each_day:6.6190910117916335},{indicative_day:"1999-6-22",each_day:-52.09335090133154},{indicative_day:"1999-6-23",each_day:-19.895050626669224},{indicative_day:"1999-6-24",each_day:68.89803207490053},{indicative_day:"1999-6-25",each_day:53.999581531974385},{indicative_day:"1999-6-26",each_day:-7.88522253767912},{indicative_day:"1999-6-27",each_day:41.02721738260017},{indicative_day:"1999-6-28",each_day:116.72465997526847},{indicative_day:"1999-6-29",each_day:92.43753206303779},{indicative_day:"1999-6-3",each_day:-19.09687030374734},{indicative_day:"1999-6-30",each_day:121.56699737783947},{indicative_day:"1999-6-4",each_day:-114.45516973727081},{indicative_day:"1999-6-5",each_day:-67.77111749505596},{indicative_day:"1999-6-6",each_day:-25.415524195467565},{indicative_day:"1999-6-7",each_day:-92.3206164018463},{indicative_day:"1999-6-8",each_day:-130.21797388379701},{indicative_day:"1999-6-9",each_day:-49.36447566419862},{indicative_day:"1999-7-1",each_day:283.49013204308403},{indicative_day:"1999-7-10",each_day:211.23500308857425},{indicative_day:"1999-7-11",each_day:154.00953589570543},{indicative_day:"1999-7-12",each_day:51.63420707710069},{indicative_day:"1999-7-13",each_day:77.57912402474953},{indicative_day:"1999-7-14",each_day:217.9471260746953},{indicative_day:"1999-7-15",each_day:284.5072392504927},{indicative_day:"1999-7-16",each_day:228.5063835129682},{indicative_day:"1999-7-17",each_day:155.73325626820306},{indicative_day:"1999-7-18",each_day:123.58497898741044},{indicative_day:"1999-7-19",each_day:124.94697507420156},{indicative_day:"1999-7-2",each_day:224.07192786099532},{indicative_day:"1999-7-20",each_day:166.6317683872436},{indicative_day:"1999-7-21",each_day:226.26889050615972},{indicative_day:"1999-7-22",each_day:234.83399639723947},{indicative_day:"1999-7-23",each_day:178.7650937472904},{indicative_day:"1999-7-24",each_day:123.82297509058336},{indicative_day:"1999-7-25",each_day:116.08010248855234},{indicative_day:"1999-7-26",each_day:148.4370615235005},{indicative_day:"1999-7-27",each_day:204.13597126761277},{indicative_day:"1999-7-28",each_day:250.96511981860567},{indicative_day:"1999-7-29",each_day:239.61336680036203},{indicative_day:"1999-7-3",each_day:-274.1465114145851},{indicative_day:"1999-7-30",each_day:176.24062728527886},{indicative_day:"1999-7-31",each_day:134.2768175492343},{indicative_day:"1999-7-4",each_day:-706.5590986341202},{indicative_day:"1999-7-5",each_day:-484.755164627645},{indicative_day:"1999-7-6",each_day:146.08319656126645},{indicative_day:"1999-7-7",each_day:484.231775418667},{indicative_day:"1999-7-8",each_day:381.8348661715918},{indicative_day:"1999-7-9",each_day:233.3861125301787},{indicative_day:"1999-8-1",each_day:147.64987699269827},{indicative_day:"1999-8-10",each_day:177.70834546830503},{indicative_day:"1999-8-11",each_day:163.27420689636932},{indicative_day:"1999-8-12",each_day:164.08341428019384},{indicative_day:"1999-8-13",each_day:159.79555416726038},{indicative_day:"1999-8-14",each_day:162.15575166223286},{indicative_day:"1999-8-15",each_day:180.29146747370447},{indicative_day:"1999-8-16",each_day:188.74206984063375},{indicative_day:"1999-8-17",each_day:184.34383100802532},{indicative_day:"1999-8-18",each_day:201.27549476994204},{indicative_day:"1999-8-19",each_day:229.33682854978528},{indicative_day:"1999-8-2",each_day:167.42741827117206},{indicative_day:"1999-8-20",each_day:213.56736204607878},{indicative_day:"1999-8-21",each_day:158.01068652982048},{indicative_day:"1999-8-22",each_day:121.47167815220288},{indicative_day:"1999-8-23",each_day:116.75432963534885},{indicative_day:"1999-8-24",each_day:127.20653483523822},{indicative_day:"1999-8-25",each_day:172.6502571625528},{indicative_day:"1999-8-26",each_day:240.42793485327698},{indicative_day:"1999-8-27",each_day:248.75158406375007},{indicative_day:"1999-8-28",each_day:193.2277243208835},{indicative_day:"1999-8-29",each_day:176.54061278954964},{indicative_day:"1999-8-3",each_day:153.14314302080066},{indicative_day:"1999-8-30",each_day:189.53548459296064},{indicative_day:"1999-8-31",each_day:88.92646334144136},{indicative_day:"1999-8-4",each_day:128.41857231901753},{indicative_day:"1999-8-5",each_day:128.86015351638517},{indicative_day:"1999-8-6",each_day:159.19615718315438},{indicative_day:"1999-8-7",each_day:201.90684551765372},{indicative_day:"1999-8-8",each_day:226.2941895777472},{indicative_day:"1999-8-9",each_day:211.01776295110122},{indicative_day:"1999-9-1",each_day:-99.70022192035898},{indicative_day:"1999-9-10",each_day:333.01813276864306},{indicative_day:"1999-9-11",each_day:263.8400890229173},{indicative_day:"1999-9-12",each_day:192.0642710201286},{indicative_day:"1999-9-13",each_day:178.56812452997875},{indicative_day:"1999-9-14",each_day:267.9625018648084},{indicative_day:"1999-9-15",each_day:377.619635341646},{indicative_day:"1999-9-16",each_day:399.58556675183723},{indicative_day:"1999-9-17",each_day:359.23461003839265},{indicative_day:"1999-9-18",each_day:341.60157663248066},{indicative_day:"1999-9-19",each_day:356.99647758196977},{indicative_day:"1999-9-2",each_day:-147.7231047989925},{indicative_day:"1999-9-20",each_day:378.9601110630621},{indicative_day:"1999-9-21",each_day:401.32143851783087},{indicative_day:"1999-9-22",each_day:400.26752618873996},{indicative_day:"1999-9-23",each_day:356.65025898735666},{indicative_day:"1999-9-24",each_day:320.65496698404866},{indicative_day:"1999-9-25",each_day:337.1039431328878},{indicative_day:"1999-9-26",each_day:352.01563146385945},{indicative_day:"1999-9-27",each_day:309.4124025345274},{indicative_day:"1999-9-28",each_day:258.31539144064516},{indicative_day:"1999-9-29",each_day:254.44324512682815},{indicative_day:"1999-9-3",each_day:-15.729425851897577},{indicative_day:"1999-9-30",each_day:257.26876945733267},{indicative_day:"1999-9-4",each_day:49.65504252009268},{indicative_day:"1999-9-5",each_day:-53.60298839071881},{indicative_day:"1999-9-6",each_day:-101.9119886917774},{indicative_day:"1999-9-7",each_day:60.63811911702271},{indicative_day:"1999-9-8",each_day:278.3418418389805},{indicative_day:"1999-9-9",each_day:364.3417978022155}],"data-25713872bd7ea71ecc827a8ebbaa6350":[{holiday:"Christmas Day",ds:"1969-12-25T00:00:00","effect size":-1454.3236428974549,indicative_day:"1999-12-25"},{holiday:"Columbus Day",ds:"1969-10-12T00:00:00","effect size":54.71341425499736,indicative_day:"1999-10-12"},{holiday:"Independence Day",ds:"1969-07-04T00:00:00","effect size":-706.5590986341202,indicative_day:"1999-7-4"},{holiday:"Labor Day",ds:"1969-09-01T00:00:00","effect size":-51.91467381565013,indicative_day:"1999-9-1"},{holiday:"Martin Luther King Jr. Day",ds:"1986-01-20T00:00:00","effect size":1.1219016959634083,indicative_day:"1999-1-20"},{holiday:"Memorial Day",ds:"1969-05-30T00:00:00","effect size":-168.9892150532758,indicative_day:"1999-5-30"},{holiday:"New Year's Day",ds:"1969-01-01T00:00:00","effect size":-935.7558852651148,indicative_day:"1999-1-1"},{holiday:"Thanksgiving",ds:"1969-11-27T00:00:00","effect size":-288.6468788930782,indicative_day:"1999-11-27"},{holiday:"Veterans Day",ds:"1969-11-11T00:00:00","effect size":-21.29044960545044,indicative_day:"1999-11-11"},{holiday:"Washington's Birthday",ds:"1969-02-22T00:00:00","effect size":-28.984745311099154,indicative_day:"1999-2-22"}]}},{mode:"vega-lite"});</script>]]></content><author><name></name></author><summary type="html"><![CDATA[Background]]></summary></entry><entry><title type="html">State Space Models</title><link href="https://bayesways.github.io/blog/2023/state-space-models/" rel="alternate" type="text/html" title="State Space Models"/><published>2023-02-01T00:00:00+00:00</published><updated>2023-02-01T00:00:00+00:00</updated><id>https://bayesways.github.io/blog/2023/state-space-models</id><content type="html" xml:base="https://bayesways.github.io/blog/2023/state-space-models/"><![CDATA[<p>State Space Models - a general overview</p> <p>Resources: Chapter 29 from <a href="https://probml.github.io/pml-book/book2.html">this book</a> <a href="https://ravinkumar.com/ssm-book-club">Related book club</a></p> <p>Feel free to bring specific topics for the following meetings (for example this work that D suggested looks interesting for down the line).</p> <p>(Note we are switching the day to Wednesday this time).</p>]]></content><author><name></name></author><category term="machine-learning"/><category term="statistics"/><category term="math-club"/><summary type="html"><![CDATA[State Space Models - a general overview]]></summary></entry></feed>